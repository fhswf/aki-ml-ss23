{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28226dc4",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Machine Learning\n",
    "### Sommersemester 2023\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der einfachste Fall der Lineraen Regression ist die Vorhersage einer (*abhängigen*) Variablen durch **eine** *unabhängige* Variable.\n",
    "Dieser Spezialfall wird daher auch *einfache Lineare Regression* (ELR) oder *univariate Lineare Regression* genannt.\n",
    "\n",
    "Wir wollen die ELR an einem einfachen Datensatz erproben.\n",
    "Dazu generieren wir uns $N=30$ Datenpunkte im Bereich $x\\in[0,10]$.\n",
    "Die $y$-Werte sollen grob entlang einer Geraden liegen.\n",
    "Wir wählen für die Gerade eine Steigung von $2$ und den Achsenabschnitt $-5$.\n",
    "\n",
    "Natürlich sollen die Punkte nicht alle **auf** dieser Geraden liegen.\n",
    "Daher fügen wir noch einen kleinen *Störfaktor* ein.\n",
    "Wir addieren zu jedem $y$-Wert einen zufälligen normalverteilten Wert mit Mittelwert 0 und Varianz 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "N = 30\n",
    "x = 10 * np.random.rand(N)\n",
    "y = 2 * x - 5 + np.random.normal(0, 2, N)\n",
    "plt.scatter(x, y);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun die *Scikit-Learn* Klasse `LinearRegression` verwenden, um ein ELR Modell für den Datensatz aufzustellen.\n",
    "Mit der `fit`-Methode passen wir das Modell an den Datensatz an.\n",
    "\n",
    "*Hinweis:* Die `fit`-Methode erwartet ein 2-dimensionales Feld als ersten Parameter. Unser `x` ist aber ein eindimensionales Array. Wir ändern daher mit der `reshape`-Methode die Dimension von `x` vor dem Aufruf von `fit` um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "x = x.reshape((-1,1))\n",
    "model.fit(x, y)\n",
    "\n",
    "print(\"Steigung:       \", model.coef_[0])\n",
    "print(\"Achsenabschnitt:\", model.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun die Modellfunktion plotten indem wir zunächst einige neue Datenpunkte erzeugen (`xplot`) und für diese Punkte den $y$-Wert über die `predict`-Methode schätzen.\n",
    "\n",
    "Wir sehen, dass die Gerade die blauen Datenpukte unseres Trainingsdatensatzes sehr gut generalisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xplot = np.linspace(0, 10, 20).reshape((-1,1))\n",
    "yplot = model.predict(xplot)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xplot, yplot, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der ``LinearRegression`` Schätzer kann nicht nur auf univariate Probleme angewendet werden, sondern er funktioniert auch für mehrere unabhängige Variablen.\n",
    "Die Modellfunktion einer allgemeinen (*multivariaten*) linearen Regression lautet:\n",
    "$$\n",
    "\\hat{y} = a_0 + a_1 x_1 + a_2 x_2 + \\cdots + a_n x_n\n",
    "$$\n",
    "\n",
    "Dabei sind die $x_i$ die einzelnen unabhängigen Variablen, die Werte $a_i$ sind die zu trainierenden Modellparameter.\n",
    "Der Parameter $a_0$, den wir beim univariaten Modell *Achsenabschnitt* genannt haben, heißt auch *Bias*-Parameter.\n",
    "Es ist der einzige Parameter, der unabhängig von den Variablen ins Modell eingeht.\n",
    "\n",
    "$\\hat{y}$ ist der geschätzte Wert der Zielvariablen für den Vektor $\\textbf{x}$.\n",
    "Für unsere Trainingsdaten kennen wir den jeweiligen exakten Wert $y$.\n",
    "Über einen Vergleich von $\\hat{y}$ und $y$ kann man feststellen, wie *gut* die Schätzung der Modellfunktion ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "N = 30\n",
    "\n",
    "# X ist eine 30x3-Matrix mit gleichverteilten\n",
    "# Zufallswerten aus [0,10]\n",
    "X = 10 * np.random.rand(N, 3)\n",
    "\n",
    "# noise ist eine Vektor mit 30 Elementen\n",
    "# aus der Normalverteilung N(0,1)\n",
    "noise = np.random.normal(0, 1, N)\n",
    "\n",
    "# Wir berechnen die Werte in y als Skalarprodukte aus dem Parameter-\n",
    "# [1.5, -2., 1.] und den Zeilen von X.\n",
    "# Als Achsenabschnitt (Bias Parameter) wählen wir 0.5\n",
    "y = .5 + np.dot(X, [1.5, -2., 1.])\n",
    "\n",
    "# Zu den exakten Ergebnissen addieren wir nun noch ein Rauschen\n",
    "y = y + noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15,8))\n",
    "__x = np.linspace(0,10)\n",
    "axs[0].scatter(X[:,0], y)\n",
    "axs[1].scatter(X[:,1], y)\n",
    "axs[2].scatter(X[:,2], y)\n",
    "axs[0].set_ylabel('y')\n",
    "axs[0].set_xlabel(r'$x_0$')\n",
    "axs[1].set_xlabel(r'$x_1$')\n",
    "axs[2].set_xlabel(r'$x_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Trainieren Sie ein `LinearRegression` Modell mit dem Datensatz `X` und geben Sie die gelernten Modellparameter $a_0$ bis $a_3$ aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4c42dc3a5700797b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing\n",
    "\n",
    "Im folgenden Beispiel verwenden wir einen Datensatz zu Immobilienpreisen in den USA für die Demonstration von Regressions-Aufgaben.\n",
    "Die Daten wurden 1990 bei der US-Volkszählung gesammelt und beschreiben Eigenschaften der Wohnverhältnisse in Bezirken des Bundesstaats Kalifornien.\n",
    "Die Zielvariable ist der Median des Hauswertes, angegeben in Hunderttausend Dollar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "#print(dataset.DESCR)\n",
    "dataset = fetch_california_housing()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz enthält folgende Merkmale:\n",
    "- **MedInc:** Median des Einkommens im Bezirk\n",
    "- **HouseAge:** Median des Hausalters im Bezirk\n",
    "- **AveRooms:** Durchschnittliche Anzahl der Zimmer pro Haushalt\n",
    "- **AveBedrms:** Durchschnittliche Anzahl der Schlafzimmer pro Haushalt\n",
    "- **Population:** Anzahl Bewohner*innen im Bezirk\n",
    "- **AveOccup:** Durchschnittliche Anzahl der Haushaltsmitglieder\n",
    "- **Latitude:** Breitengrad des Bezirks\n",
    "- **Longitude:** Längengrad des Bezirks\n",
    "\n",
    "Die Zielvariable `target` ist der Preis der jeweiligen Häuser in Hunderttausend US-Dollar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preise = dataset.target\n",
    "print(f\"Der Wert der Häuser reicht von {int(np.min(preise)*1000)} bis {int(np.max(preise)*1000)} USD\")\n",
    "print(f\"Im Mittel kosten die Häuser {int(np.mean(preise)*1000)} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Teilen Sie den Datensatz in einen Trainings- und einen Testdatensatz auf. Der Umfang der Trainingsdaten soll 70% der Gesamtdaten sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68d3b403708a9567",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = (None, None, None, None)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-67e4df466defad75",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 68 < X_train.size * 100 / (X_test.size + X_train.size) < 72, \"Keine 70% Trainingsdaten\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Verwenden Sie die Trainingsdaten, um ein lineares Regressionsmodell `model` zu trainieren.\n",
    "Berechnen Sie damit eine Schätzung `y_vorhersage` für die Testdaten.\n",
    "Danach berechnen wir den *mittleren absoluten Fehler* und überprüfen damit, wie gut unser Modell die Preise der Häuser schätzen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42d6643b64c7304d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "model = None\n",
    "y_vorhersage = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "mittlerer_fehler = np.sum(np.abs(y_vorhersage-y_test))/len(y_vorhersage)\n",
    "print(f\"Der mittlere Fehler der Vorhersage liegt bei {int(mittlerer_fehler*100000)} USD\")\n",
    "\n",
    "err_percent = mean_absolute_percentage_error(y_test, y_vorhersage)\n",
    "print(f\"Damit liegen wir im Mittel ca. {int(err_percent*100)}% daneben\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quellen:\n",
    "[1] Jake VanderPlas, [*Python Data Science Handbook*](https://jakevdp.github.io/PythonDataScienceHandbook), O'Reilly, 2016.\\\n",
    "[2] Wolf Riepl, [*Machine Learning mit R und caret: GBM optimieren (Gradient Boosting Machine)*](https://statistik-dresden.de/archives/14967), Artikel auf https://statistik-dresden.de,  Veröffentlicht am 23.01.2018 (zugegriffen am 27.04.2021)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
