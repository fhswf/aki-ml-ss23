{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8f21d7",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Machine Learning\n",
    "### Sommersemester 2023\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bewertung binärer Klassifikatoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook wollen wir betrachten, wie die man die Güte von binären Klassifikatoren bewerten kann.\n",
    "Als Beispiel dient uns der [Heart Failure Prediction](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction) Datensatz von [Kaggle](www.kaggle.com).\n",
    "In diesem Datensatz wurden 5 Herzdatensätze aus verschiedenen Ländern über 11 gemeinsame Merkmale kombiniert.\n",
    "Diese Merkmale stellen medizinischen Werte dar, die Zielvariable sagt aus, ob die entsprechende Person herzkrank ist.\n",
    "\n",
    "Die folgende Liste beschreibt die Merkmale und die Zielvariable des Datensatzes:<br>\n",
    "**Age**: Alter des Patienten [Jahre]<br>\n",
    "**Sex**: Geschlecht des Patienten [M: Männlich, F: Weiblich]<br>\n",
    "**ChestPainType**: Art der Brustschmerzen [TA: Typische Angina, ATA: Atypische Angina, NAP: Nicht-Anginaler Schmerz, ASY: Asymptomatisch]<br>\n",
    "**RestingBP**: Ruheblutdruck [mm Hg]<br>\n",
    "**Cholesterin**: Serumcholesterin [mm/dl]<br>\n",
    "**FastingBS**: Nüchtern-Blutzucker [1: wenn FastingBS > 120 mg/dl, 0: sonst]<br>\n",
    "**RestingECG**: Ruhe-Elektrokardiogramm-Ergebnisse [Normal: Normal, ST: mit ST-T-Wellen-Anomalie, LVH: mit Hypertrophie]<br>\n",
    "**MaxHR**: maximal erreichte Herzfrequenz [Numerischer Wert zwischen 60 und 202]<br>\n",
    "**ExerciseAngina**: Belastungsangina [J: Ja, N: Nein]<br>\n",
    "**Oldpeak**: ST-Senkung = ST [Numerischer Wert]<br>\n",
    "**ST_Slope**: die Steigung des Spitzen-ST-Segments bei Belastung [Up: ansteigend, Flat: flach, Down: absteigend]<br>\n",
    "**HeartDisease**: Ausgabeklasse [1: Herzkrankheit, 0: Normal]<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir starten mit dem Herunterladen des Datensatzes und dem Aufteilen in Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/fhswf/datasets/raw/main/heart_imb.csv\"\n",
    "dfile = \"./heart_imb.csv\"\n",
    "\n",
    "if not os.path.isfile(dfile):\n",
    "    urllib.request.urlretrieve(url, dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dfile)\n",
    "X, y = df.drop(columns=[\"HeartDisease\"]), df[\"HeartDisease\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "distrib = y_train.value_counts().values\n",
    "print(f\"In den Traingsdaten sind {distrib[0]} gesunde und {distrib[1]} herzkranke Personen\")\n",
    "distrib = y_test.value_counts().values\n",
    "print(f\"Im Testdatensatz sund {distrib[0]} gesunde und {distrib[1]} herzkranke Personen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Grundlage für unsere Bewertungen trainieren wir zunächst ein `DummyClassifier` Modell.\n",
    "Das ist kein Klassifikator im eigentlichen Sinn, denn der `DummyClassifier` verwendet keines der Merkmale zur Vorhersage der Zielariablen. Das Modell schaut sich lediglich die Verteilung der Labels an und schätzt dann anhand sehr einfacher Regeln. In unserem Fall verwenden wir die Regel `most_frequent`, was bedeutet, dass immer die am häufigsten vorkommende Klasse vorausgesagt wird. Dies ist bei uns die Klasse 0, also die Klasse für *gesunde Personen*.\n",
    "\n",
    "Der *DummyClassifier* schneidet für unsere Daten mit 90% *Treffergenauigkeit* (***accuracy***) sehr gut ab. Überlegen Sie sich, warum das bei unseren Daten der Fall ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "acc_dummy = dummy.score(X_test, y_test)\n",
    "print(f\"Score (Dummy): {acc_dummy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wollen wir ein *echtes* Modell trainieren und verwenden hier die Logistische Regression.\n",
    "Da unser Datensatz numerische und kategorische Merkmale enthält, müssen wir ihn noch Transformieren.\n",
    "Damit die Merkmale in etwa proportional zueinander gewichtet werden, müssen die Spalten noch normalisiert bzw. standardisiert werden.\n",
    "\n",
    "Außerdem sollten im Vorfeld fehlende Werte ersetzt oder die zugehörigen Datenpunkte gelöscht werden. Da unser Datensatz vollständig ist, benötigen wir diesen Schritt hier eigentlich nicht, nehmen ihn aber zur Vollständigkeit mit auf.\n",
    "\n",
    "Die Transformationsschritte müssen beim Training und der Inferenz durchgeführt. Das führt zu recht vielen Aufrufen und damit tendenziell zu eher unübersichtlichem Code.\n",
    "Daher verwenden wir hier eine *sklearn Pipeline* die mehrere Vorverarbeitungsschritte sowie das Modell in einem Objekt zusammenfasst.\n",
    "\n",
    "Bei **numerischen Merkmalen** werden zunächst fehlende Werte durch den Mittelwert ersetzt, danach werden die Spaltewerte standardisiert.\n",
    "Die **kategorischen Merkmale** werden per One-Hot-Coding umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "numeric_features = X_train.select_dtypes(exclude=\"object\").columns.values\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = X_train.select_dtypes(\"object\").columns.values\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der für die Vorverarbeitung zuständige `ColumnTransformer` wird nun mit einem `LogisticRegression` Modell in einer *Pipeline* zusammengefasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Verwenden Sie die Pipeline `logreg`, um die *Accuracy* für die Testdaten zu bestimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ddc176e753960a93",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "acc_logreg = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(f\"Score (Log Regression): {acc_logreg:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5191f89bbbe20532",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "assert_almost_equal(acc_logreg, 0.9217391304347826, decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf unsere Daten angewendet, erzielt das Modell eine *Treffergenauigkeit* (***accuracy***) von 92.2%, ist also nur geringfügig besser als unser *DummyClassifier*. Bedeutet dies, dass unser Modell schlecht ist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konfusionsmatrix \n",
    "\n",
    "Die Konfusionsmatrix (engl. *Confusion Matrix*) ist ein wichtiges Hilfsmittel zur Bewertung von Klassifikatoren.\n",
    "Auf der x-Achse Confusion Matrix sind üblicherweise die vorhergesagten Klassen aufgetragen, auf der y-Achse die tatsächlichen Klassen. Bei einer binären Klassifikation besitzt die Matrix also 4 Zellen, bzw. Einträge.\n",
    "\n",
    "Auf der obere Zeile der binären Confusion Matrix sind die Datenpukte aufgetragen, die *tatsächlich* das Merkmal `0` besitzen (`y_test==0`), also hier die *Gesunden*. Auf der zweiten Zeile stehen die Datenpunkte, die *Herzkranken* zugeordnet sind (`y_test==1`).\n",
    "\n",
    "In der ersten Spalte der Confusion Matrix sind die Datenpukte aufgetragen, die vom Klassifikator das Ergebnis `0` zugeordnet bekommen (`prediction==0`), auf der zweiten Zeile diejenigen, für die das Modell eine `1` vorhersagt (`prediction==1`).\n",
    "\n",
    "Die Zellen oben links und unten rechts sind also richtig klassifizierte, in den Zellen oben rechts und unten links stehen falsch klassifizierte Datenpunkte.\n",
    "Für die 4 Zellen der Matrix haben sich folgende englische Begriffe auch im Deutschen etabliert:\n",
    "- Richtig als positiv klassifiziert: *true positives* (**TP**)\n",
    "- Fälschlicherweise als positiv klassifiziert: *false positives* (**FP**)\n",
    "- Richtig als negativ klassifiziert: *true negatives* (**TN**)\n",
    "- Fälschlicherweise als negativ klassifiziert: *false negatives* (**FN**)\n",
    "\n",
    "Die *Accuracy* stellt die richtig klassifzierten in Relation zu allen Datenpunkten.\n",
    "Das ist aber häufig nicht das Kriterium, das zur Bewertung des Klassifikators sinnvoll ist.\n",
    "\n",
    "Betrachten wir unseren Fall mit dem Prediktor für Herzkrankheiten.\n",
    "Das Modell sollte möglichst alle Personen, die tatsächlich herzkrank sind auch als krank erkennen.\n",
    "Der Fehler, dass eine gesunde Person fälschlicherweise als herzkrank klassifiziert wird, ist eher zu akzeptieren.\n",
    "\n",
    "Schauen wir uns die Confusion Matrix mit *sklearn* an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from packaging import version\n",
    "if version.parse(sklearn.__version__) > version.parse(\"0.24\"):\n",
    "    from sklearn.metrics import ConfusionMatrixDisplay\n",
    "    cm_function = ConfusionMatrixDisplay.from_estimator\n",
    "else:\n",
    "    from sklearn.metrics import plot_confusion_matrix\n",
    "    cm_function = plot_confusion_matrix\n",
    "    \n",
    "cm_function(\n",
    "    logreg, X_test, y_test,\n",
    "    display_labels=[\"Gesund\", \"Herzkrank\"],\n",
    "    values_format=\"d\", cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So betrachtet, sieht unser Klassifikator nicht mehr so gut aus.\n",
    "Von den insgesamt 23 kranken Personen werden immerhin 7 als gesund klassifiziert.\n",
    "\n",
    "Das Verhältnis von richtig als positiv klassifizierten Datenpunkten zu allen tatsächlich positiven, bezeichnet man als Sensitivität (*senitivity* oder auch ***recall***).\n",
    "Das Verhältnis von richtig als positiv klassifizierten Datenpunkten zu allen als positiven klassifizierten Datenpunkten bezeichnet man als Relevanz (***precision***). \n",
    "Ein Maß, das beide Kriterien gleich gewichtet miteinbezieht, ist der F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = logreg.predict(X_test)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, pred).ravel()\n",
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Berechnen Sie jeweils den **recall**, die **precision** und den **F1-Score** für das Modell. Verwenden Sie dazu die Variablen `TN`, `FP`, `FN` und `TP`, wie oben berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9b9599c7f85f6e7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "recall = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"TP = %d, FN = %d\" % (TP, FN))\n",
    "print(\"Recall: %0.4f\" % (recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4738de7ffa579fd5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "assert_almost_equal(recall, 0.6956521739130435, decimal=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6ec28f4c519c113",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "precision = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"TP = %d, FP = %d\" % (TP, FP))\n",
    "print(\"Precision: %0.4f\" % (precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e4e99f9d9e3b2e5a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "assert_almost_equal(precision, 0.5925925925925926, decimal=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87954bf815cd6c64",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "f1 = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"f1-score: %0.4f\" % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fef0ea5cd3bfc5f8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "assert_almost_equal(f1, 0.64, decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da man diese und weitere Metriken recht häufig benötigt, besitzt *sklearn* eigene Methoden zur Berechnug im Modul `metrics`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def print_scores(predictions, y_test):\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    pre = precision_score(y_test, predictions)\n",
    "    rec = recall_score(y_test, predictions)\n",
    "    f1s = f1_score(y_test, predictions)\n",
    "    print(f\"accuracy={acc:.3f} precision={pre:.3f} recall={rec:.3f} f1={f1:.3f}\")\n",
    "\n",
    "print_scores(logreg.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivität verbessern\n",
    "\n",
    "Wir haben erörtert, dass für unsere Anwendung die Sensitivität das wichtigste Kriterium ist und gerade in diesem Bereich schneidet unser Klassifikator mit einem Recall-Wert von ca. 70% nicht gut ab.\n",
    "Es stellt sich die Frage, ob und wie wir den *recall*, ggf. auch zu Ungunsten der Relevanz (*precision*) und Treffergenauigkeit (*accuracy*), verbessern können.\n",
    "\n",
    "Dazu schauen wir etwas genauer in unser Logistisches Regressionsmodell.\n",
    "Das Modell berechnet im Prinzip für jeden Datenpunkt eine *Wahrscheinlichkeit*, zur Klasse `1` zu gehören.\n",
    "Am Ende wird dann ein Schwellenwert (engl. *threshold*) verwendet um die binäre Klasse zu bestimmen.\n",
    "Üblicherweise wird als Schwellenwert 0.5 gewählt.\n",
    "\n",
    "Die berechneten Wahrscheinlichkeiten können wir für unser `LogisticRegression` Modell mit der Methode `predict_proba` berechnen.\n",
    "Schauen wir nun an, wo die berechneten Wahrscheinlichkeiten über dem Wert `0.5` liegen und vergleichen wir das Ergebnis mit den tatsächlichen Labels (`y_test`), bekommen wir die gleichen Ergebnisse wie oben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logreg.predict_proba(X_test)[:, 1] > .5\n",
    "print_scores(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir wollen, dass ein Datenpunkt *eher als herzkrank klassifiziert* werden soll, müssen wir den Schwellenwert herabsetzen.\n",
    "Schauen wir uns also an was passiert, wenn wir den Schwellenwert auf `0.2` ändern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logreg.predict_proba(X_test)[:, 1] > .2\n",
    "print_scores(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Recall hat sich deutlich verbessert.\n",
    "Dass die Accuracy und die Precision zurückgegangen sind, war erwartet.\n",
    "\n",
    "Schauen wir uns die Ergebnisse nochmal in einer Confusion Matrix an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version.parse(sklearn.__version__) > version.parse(\"0.24\"):\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, pred,\n",
    "        display_labels=[\"Gesund\", \"Herzkrank\"],\n",
    "        values_format=\"d\", cmap='Blues')\n",
    "else:\n",
    "    print(\"Bitte sklearn updaten!\")\n",
    "    print(\"z.B. mit: conda install scikit-learn=1.0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-Recall- und ROC-Kurve\n",
    "\n",
    "Wie sich die Verschiebung des Schwellenwertes auswirkt, kann grafisch mit der *Precision-Recall* (PR) oder der *Receiver Operating Characteristic* (ROC) Kurve dargestellt werden.\n",
    "\n",
    "Bei der PR_Kurve stellt man auf der x-Achse die Relevanz (*precision*) und auf der y-Achse die Sensitivität (*recall*) dar.\n",
    "Die Kurve zeigt den Verlauf beider Werte bei steigendem Schwellenwert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(\n",
    "    y_test, logreg.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "plt.plot(precision, recall, label=\"PR Kurve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(\n",
    "    precision_score(y_test, logreg.predict(X_test)),\n",
    "    recall_score(y_test, logreg.predict(X_test)),\n",
    "    \"ob\",\n",
    "    markersize=10,\n",
    "    label=\"Schwellenwert 0.5\"\n",
    ")\n",
    "\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5a9751346e1bbe4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**Aufgabe:** Die Kurve scheint hier *zurückzuspringen* weil sich *Recal* und *Precision* gleichzeitig verschlechtern. Haben Sie eine Idee, warum das sein kann?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d77f8d8a8612858c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die ROC-Kurve betrachtet auf der y-Achse ebenfalls den *Recall* und auf der x-Achse die ***Ausfallrate*** (engl. *false positive rate*, FPR).\n",
    "\n",
    "Da der *Recall* auch als *true positive rate* angesehen werden kann, werden bei der ROC Kurve also die *richtig als positiv Klassifizierten* den *falsch als positiv Klassifizierten* gegenübergestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, logreg.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label=\"ROC Kurve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "pred = logreg.predict(X_test)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, pred).ravel()\n",
    "\n",
    "plt.plot(\n",
    "    FP/(FP+TN),\n",
    "    TP/(TP+FN),\n",
    "    \"ob\",\n",
    "    markersize=10,\n",
    "    label=\"Schwellenwert 0.5\"\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c35e1af38b8ef3c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**Aufgabe:** Die ROC-Kurve steigt hier monoton an. Ist das immer der Fall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6f33bd914d880510",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Klassifikation bei unausgewogenen Datensätzen\n",
    "\n",
    "Sie haben sicher schon bemerkt, dass ein Problem mit unserem Datensatz darin besteht, dass die Verteilung der Zielvariablen sehr unausgeglichen ist.\n",
    "Wir haben fast 10-mal mehr Datenpunkte, die zu *gesunden* Personen ghören.\n",
    "Damit sind die *Herzkranken* im Datensatz stark unterrepräsentiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib = y_train.value_counts().values\n",
    "print(f\"In den Traingsdaten sind {distrib[0]} gesunde und {distrib[1]} herzkranke Personen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Möglichkeit, mit unausgewogenen Datensätzen umzugehen, ist Under- bzw. Oversamplig.\n",
    "Beim **Oversampling** verden Datenpunkte aus der unterrepräsentierten Klasse dupliziert.\n",
    "**Undersampling** löscht nach dem Zufallsprinzip Datenpunkte aus der überrepräsentierten Klasse.\n",
    "Da so der Datensatz aktiv *verkleinert* wird, kann Undersampling dazu führen, dass wertvolle Informationen verloren gehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Alternative zu Under- bzw. Oversamplig ist, die Fehler beim Modell-Training unterschiedlich zu gewichten.\n",
    "Falsch klassifizierte *Kranke* könnten stärker gewichtet werden, als falsch klassifizierte *gesunde* Personen.\n",
    "Dies würde das Modell dazu zwingen, die richtigen Ergebnisse für die Klasse 1 (=*herzkrank*) zu bevorzugen.\n",
    "\n",
    "Die Klassen-Gewichte können in *sklearn* über den Parameter `class_weights` eingestelt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Erstellen Sie eine *sklearn Pipeline* genau wie im Beispiel oben.\n",
    "Fügen Sie zu dem `LogisticRegression`-Modell den Parameter `class_weight` hinzu.\n",
    "Der Wert des des Parameters ist ein *Dictionary*, in dem die Klassen als *Keys* und die zugehörigen Gewichte als *Values* aufgeführt sind.\n",
    "Wählen Sie für die Klasse `0` das Gewicht `1` und für die Klasse `1` das Gewicht `10`.\n",
    "\n",
    "*Zur Erinnerung: Das folgende Dictionary `d` ordnet den Keys `4` und `5` die Values `'Hallo'` bzw. `'Welt'` zu*\n",
    "```python\n",
    "d = {4: 'Hallo', 5: 'Welt'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41a1157edc980dad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "logreg_cw = None\n",
    "# Legen Sie die Pipeline unter dem Namen logreg_cw an!\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "logreg_cw.fit(X_train, y_train)\n",
    "print_scores(logreg_cw.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-893abf46e6b69140",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "__acc = logreg_cw.score(X_test, y_test)\n",
    "assert_almost_equal(__acc, 0.8478260869565217, decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neben fest angegeben Klassen-Gewichten kann `class_weight` auch auf den Wert `'balanced'` gesetzt werden. In diesem Fall werden die Gewichte aus der Verteilung der Labels berechnet.\n",
    "\n",
    "**Aufgabe:** Erzeugen Sie eine neue Pipeline mit einem `LogisticRegression`-Modell, wobei der Parameter `class_weight` auf den Wert `'balanced'` gesetzt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-54c81cdc6f493cee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "logreg_bal = None\n",
    "# Legen Sie die Pipeline unter dem Namen logreg_bal an!\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "logreg_bal.fit(X_train, y_train)\n",
    "print_scores(logreg_bal.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3d9da51f64f78373",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "__acc = logreg_bal.score(X_test, y_test)\n",
    "assert_almost_equal(__acc, 0.8565217391304348, decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelle vergleichen\n",
    "\n",
    "Wir haben nun unterschiedliche Modelle erzeugt und wollen diese miteinander vergleichen.\n",
    "Dazu können wir die verschiedenen *Scores* (accuracy, precision, recall, etc.) zurate ziehen.\n",
    "Allerdings gehen diese Werte alle von einem Schwellenwert von 0.5 aus.\n",
    "\n",
    "Wenn wir wissen wollen, welches Modell *insgesamt* besser ist, müssen wir auch unterschiedliche Schwellenwerte betrachten.\n",
    "Dafür können wir die ROC-Kurven in ein Diagramm plotten.\n",
    "\n",
    "Ein Modell ist umso besser, je *eckiger* der Verlauf der Kurve ist und umso mehr die Kurve die anderen ROC-Kurven *umschließt*.\n",
    "Mathematisch gesehen, ist also die Fläche unter der ROC-Kurve ausschlaggebend für die Güte des Modells hinsichtlich der Sensitivität.\n",
    "Diese Fläche wird auch als *Area Under Curve* (AUC) bezeichnet und kann mit der Methode `roc_auc_score` aus dem Modul `sklearn.metrics` berechnet werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr0, tpr0, _ = roc_curve(y_test, logreg.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr0, tpr0, label=\"ROC Original\")\n",
    "fpr1, tpr1, _ = roc_curve(y_test, logreg_cw.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr1, tpr1, label=\"ROC Class Weight\")\n",
    "fpr2, tpr2, _ = roc_curve(y_test, logreg_bal.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr2, tpr2, label=\"ROC Balanced\")\n",
    "\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "plt.xlim([-.02, .5])\n",
    "plt.legend(loc=\"best\", prop={'size': 14});\n",
    "\n",
    "\n",
    "print(f\"AUC Original: {roc_auc_score(y_test, logreg.predict(X_test)):.3f}\")\n",
    "print(f\"AUC Class Weight: {roc_auc_score(y_test, logreg_cw.predict(X_test)):.3f}\")\n",
    "print(f\"AUC Balanced: {roc_auc_score(y_test, logreg_bal.predict(X_test)):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
