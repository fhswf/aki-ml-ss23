{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb27970",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Machine Learning\n",
    "### Sommersemester 2023\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce9605",
   "metadata": {},
   "source": [
    "##  Multi-Layer Perceptron mit Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e8c73",
   "metadata": {},
   "source": [
    "Für dieses Aufgabenblatt benötigen wir die Bibliothek Keras.\n",
    "Seit Version 1.4 von TensorFlow ist Keras Teil der TensorFlow Core API und kann damit direkt aus dem Framework hinaus genutzt werden.\n",
    "Fall Sie TensorFlow noch nicht installiert haben, sollten Sie das nun erledigen, z.B. über den Paketmanager *pip*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "except:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install tensorflow\n",
    "    #import sys\n",
    "    #!conda install --yes --prefix {sys.prefix} -c conda-forge tensorflow\n",
    "    import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612606ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lade Tensorflow in Version\", tf.__version__)\n",
    "from packaging import version\n",
    "assert version.parse(tf.__version__) > version.parse(\"2.3.0\"), \"TF 2.3.0 hat einen Bug beim Speichern und Laden von Modellen. Siehe [2]\"\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa8428",
   "metadata": {},
   "source": [
    "In diesem Aufgabenblatt wollen wir ein recht einfaches Klassifikationsproblem einmal mit logistischer Regression (mit *Scikit-learn*) und dann mit einem Multi-Layer Perceptron (MLP) mit der Keras Sequential API untersuchen.\n",
    "Der Datensatz enthält knapp 15.000 Einträge aus einer Mitarbeiter-Datenbank.\n",
    "Die darin enthaltenen Informationen geben z.B. Auskunft darüber, wie lange eine Person schon in der Firma ist, wie hoch die Gehaltsstufe ist oder zufrieden die Person im Betrieb ist.\n",
    "Als Label wollen wir die Information verwenden, ob die Person die Firma verlassen hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/fhswf/datasets/raw/main/MA.csv\"\n",
    "dfile = \"./MA.csv\"\n",
    "\n",
    "if not os.path.isfile(dfile):\n",
    "    urllib.request.urlretrieve(url, dfile)\n",
    "\n",
    "data=pd.read_csv('MA.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580e55b",
   "metadata": {},
   "source": [
    "Wir sehen, dass die meisten Merkmale numerisch sind, nur *Bereich* und *Gehalt* sind kategorisch.\n",
    "Die Spalte Gehalt hat allerdings eine Sortierung, d.h. wir habe es hier eigentlich mit einem *ordinalen* Merkmal zu tun.\n",
    "Daher übersetzen wir die Klassen (*high*, *low*, und *medium*) in ganze Zahlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3379c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df['Gehalt'] = pd.Categorical(df['Gehalt'], categories=['high', 'medium', 'low'])\n",
    "df['Gehalt'] = df.Gehalt.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc256cc9",
   "metadata": {},
   "source": [
    "**Aufgabe: Transformieren Sie das Merkmal \"Bereich\" per One-Hot-Kodierung in numerische Merkmale. Selektieren Sie als Labels `y` die Spalte `Firma_verlassen` aus dem Datensatz. Der Datensatz `X` soll alle Spalten bis auf die Labels enthalten.**\n",
    "\n",
    "*Hinweis:* Für die One-hot-Kodierung können Sie die Funktion `pandas.get_dummies` verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b76ab",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f0efbb01928c16f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y = None\n",
    "X = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1434e80",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e0728c8b97d9a320",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert X.shape == (14999, 18)\n",
    "assert y.shape == (14999,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb3fe9",
   "metadata": {},
   "source": [
    "**Aufgabe: Standardisieren Sie die Merkmale in `X`**\n",
    "\n",
    "*Hinweis:* Sie können dazu die Klasse `StandardScale` aus `sklearn import preprocessing` verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2d9f6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-44692f716a6db008",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaled = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03602b1b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8727aa669141334e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert all(np.isclose(X_scaled.mean(axis=0), 0, atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c86a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "FEATURES = X_train.shape[1]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feefeec",
   "metadata": {},
   "source": [
    "**Aufgabe: Trainieren Sie ein Logistic Regression Modell mit den Trainingsdaten. Berechnen Sie die Accuracy `ca` für die Testdaten.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4134e0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ee281193d40ccbf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ca = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"Accuracy = %.2f%%\" % (ca*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48204a43",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1d33e311caf52b10",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(ca, 0.78888888888, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c4fd7",
   "metadata": {},
   "source": [
    "### MLP mit Keras\n",
    "\n",
    "Wir wollen nun für die gleichen Daten ein Multi-Layer Perzeptron mit Keras aufstellen.\n",
    "Dazu lesen wir zunächst die NumPy Arrays in Tensorflow `Datasets` ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8495eea",
   "metadata": {},
   "source": [
    "Da wir das Mini-Batch Gradientenverfahren verwenden wollen, teilen wir unseren Datensatz in kleiner *Batches* auf.\n",
    "Zuvor \"mischen\" wir die Datenpunkte durch, damit die Punkte in den einzelnen Batches möglichst unsortiert sind und damit ein einzelner Batch die Eigenschaften des kompletten Datensatzes möglichst gut repräsentiert.\n",
    "Die Idee dahinter ist, das der Gradient, den wir für den Mini-Batch berechnen, möglichst ähnlich zu dem Gradienten der kompletten Daten ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c31c3dd",
   "metadata": {},
   "source": [
    "**Aufgabe: Stellen Sie nun ein sequentielles Keras Modell auf. Es soll mindestens 3 Schichten haben. Als Aktivierungsfunktion verwenden Sie `sigmoid`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a475313",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4166fd25ec30f2fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Modell definieren\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(FEATURES,)))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963af0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-05490d58dcc75aad",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(model.layers)>2, \"Das Modell soll mindestens 3 Schichten haben\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91051faf",
   "metadata": {},
   "source": [
    "Nun erzeugen wir das Modell mit der Funktion `compile`. Dabei geben wir das Optimierungsverfahren, die (Art der) Kostenfunktion sowie die zu berechnenden Metriken an.\n",
    "\n",
    "**Aufgabe: Wählen Sie eine geeignet Kostenfunktion aus. Als Metrik soll die Accuracy berechnet werden.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2446004",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2c57d1c328abf34",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Modell erzeugen\n",
    "optimizer = 'sgd'\n",
    "loss = None\n",
    "metrics = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "model.compile(optimizer, loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf956e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b754e860d06794cd",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert model.trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2819f62",
   "metadata": {},
   "source": [
    "Nun trainieren wir das Modell und geben die Accuracy für die Testdaten aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modell trainieren\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.3)\n",
    "\n",
    "#Trainiertes Modell auswerten\n",
    "test_loss, test_acc = model.evaluate (X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b17fa4b",
   "metadata": {},
   "source": [
    "Die Ergebnisse sind etwas ernüchternd. Wir sehen, dass bereits nach einer Epoche das Modell ähnlich gute Ergebnisse erzielt, wie die logistische Regression, diese Ergebnisse aber durch weitere Optimierungschritte nicht mehr verbessert werden.\n",
    "Sie können nun versuchen, die Ergebnisse durch Ändern des Modells zu verbessern, etwa durch die Verwendung einer anderen Aktivierungsfunktion, die ein schnelleres Lernverahlten aufweist (z.B. `tanh`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd34c86",
   "metadata": {},
   "source": [
    "### Hausnummern erkennen\n",
    "\n",
    "Wir wollen daher noch einen Weiteren Datensatz betrachten, der deutlich komplexer ist.\n",
    "Es handelt sich um Fotos, bzw. um Bildausschnitte die einzelne Ziffern von Hausnummern zeigen.\n",
    "Damit ähneln die Daten dem MNIST Datensatz.\n",
    "Da es sich um (Farb-) Fotos handelt, die zudem noch recht verrauscht sind, ist das Problem, die Ziffern zu erkennen, aber deutlich schwieriger.\n",
    "\n",
    "Wir laden zunächst die Bidler von der URL http://ufldl.stanford.edu/housenumbers herunter.\n",
    "Details zum Datensatz finden Sie in [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "url = [f\"http://ufldl.stanford.edu/housenumbers/{n}_32x32.mat\" for n in (\"train\", \"test\")]\n",
    "dfile = [f\"./{n}_32x32.mat\" for n in (\"train\", \"test\")]\n",
    "\n",
    "\n",
    "for i in range(len(url)):\n",
    "    if not os.path.isfile(dfile[i]):\n",
    "        urllib.request.urlretrieve(url[i], dfile[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615fded",
   "metadata": {},
   "source": [
    "Die Daten liegen im `.mat`-Format vor, dass zumeist in Matlab verwendet wird.\n",
    "Wir importieren die Daten über die Funktion `scipy.io.loadmat` und extrahieren dann die Attribute und Labels jeweils aus den Test- und Trainings-Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8232780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "train_raw = loadmat('./train_32x32.mat')\n",
    "test_raw = loadmat('./test_32x32.mat')\n",
    "                   \n",
    "train_images = np.array(train_raw['X'])\n",
    "test_images = np.array(test_raw['X'])\n",
    "\n",
    "train_labels = train_raw['y']\n",
    "test_labels = test_raw['y']\n",
    "                   \n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e61c31",
   "metadata": {},
   "source": [
    "Wenn Sie sich die Dimension der Datensätze ansehen, stellen Sie fest, dass die Daten unpassend strukturiert sind.\n",
    "In den ersten Dimensionen haben wir die (RGB) Pixel der einzelnen Bilder, in der letzten Dimension die einzelnen Bilder.\n",
    "Daher sortieren wir die Dimensionen, bzw. die Axen unserer Datensätze um, sodass die erste Dimension dem Index eines Bildes entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434da5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the axes of the images\n",
    "\n",
    "train_images = np.moveaxis(train_images, -1, 0)\n",
    "test_images = np.moveaxis(test_images, -1, 0)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3364cbb",
   "metadata": {},
   "source": [
    "Nun können wir ein zufälliges Bild ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac458227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "# Plot a random image and its label\n",
    "\n",
    "plt.imshow(train_images[random.randint(0,len(train_images))])\n",
    "plt.show()\n",
    "\n",
    "print('Label: ', train_labels[13529])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float64')\n",
    "test_images = test_images.astype('float64')\n",
    "\n",
    "train_labels = train_labels.astype('int64')\n",
    "test_labels = test_labels.astype('int64')\n",
    "\n",
    "train_images /= 255.0\n",
    "test_images /= 255.0\n",
    "\n",
    "train_labels -= 1\n",
    "test_labels -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ba03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_labels.max()==9, \"\"\"Die Label stimmen nicht.\n",
    "Das kann passieren, wenn Sie eine Zelle doppelt ausgeführt haben.\n",
    "Importieren Sie den Datensatz noch einmal\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48efba8d",
   "metadata": {},
   "source": [
    "**Aufgabe: Stellen Sie ein sequenziellen Keras Model auf. Das Modell soll 2 Schichten haben.\n",
    "Die erste Schicht soll 128 Neuronen besitzen und ReLU als Aktivierungsfunktion verwenden.\n",
    "Die zweite Schicht soll 10 Neuronen besitzen und als Aktivierungsfunktion die Softmax-Funktion verwenden.\n",
    "Bei der Eingabeschicht orientieren Sie sich am besten an den MNIST Beispielen für Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc545d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c7e24dc8ece37f87",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Modell definieren\n",
    "\n",
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560dfa7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3bfeb803a294d520",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(model.layers) == 3, \"Das Model soll eine Input Schicht und 2 Hidden Layers besitzen\"\n",
    "assert model.layers[1].output_shape[1] == 128\n",
    "assert model.layers[2].output_shape[1] == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f87e0",
   "metadata": {},
   "source": [
    "**Aufgabe: Wählen Sie geeignete Parameter für das Modell aus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac9d9f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7d0db676fc0b439c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Modellparameter\n",
    "optimizer =None\n",
    "loss = None\n",
    "metrics = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "#Modell erzeugen\n",
    "model.compile(optimizer,loss,metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d963b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fb50d0c7f88f2ef7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert model.trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da8d88",
   "metadata": {},
   "source": [
    "Nun können wir das Modell trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77350255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modell trainieren\n",
    "history = model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddef0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainiertes Modell auswerten\n",
    "test_loss, test_acc = model.evaluate (test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f86b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a342be",
   "metadata": {},
   "source": [
    "Den Kurven der Accuracy und der Kostenfunktion nach zu urteilen, kann das Modell noch weiter verbesser werden.\n",
    "Um bei gleichen (Hyper-)Parametern das Modell nicht immer neu trainieren zu müssen ist es sinnvoll, die Modellparameter in einer Datei zu speichern.\n",
    "\n",
    "**Aufgabe:**\n",
    "\n",
    "1. **Schreiben Sie den Code von oben so um, dass nur dann ein Modell erzeugt wird, wenn im aktuellen Verzeichnis kein Verzeichnis  `my_model` existiert. Wenn Sie existiert, soll das Modell aus diesem Verzeichnis geladen werden.**\n",
    "1. **Fitten Sie das Modell über 5 Epochen und speichern Sie das Modell danach unter dem Namen `my_model` im TensorFlow SavedModel Format.**<br> *Hinweis: Wenn sie die Methode `save()` auf dem Keras Modell aufrufen, ist das SavedModel Format der Standard*\n",
    "1. **Wenn Sie die Code-Zelle erneut ausführen, sollten das vortrainierte Model weiterverwendet werden**\n",
    "1. **Beobachten Sie, ob sich die Accuracy auf den Testdaten verbessert.**\n",
    "*Hinweis: Sie können die Methoden `keras.models.load_model` und `save` zum Laden und Speichern des Modells verwenden*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d21e1c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3aadb59a3b5bb73e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mname = \"my_model.tf\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8865de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainiertes Modell auswerten\n",
    "test_loss, test_acc = model.evaluate (test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63cbcca",
   "metadata": {},
   "source": [
    "### Referenzen\n",
    "\n",
    "[1] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng. *\"Reading Digits in Natural Images with Unsupervised Feature Learning\"*,  NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011.\n",
    "\n",
    "[2] Tensorflow Github Issue #42459 [Accuracy is lost after save/load #42459](https://github.com/tensorflow/tensorflow/issues/42459)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
