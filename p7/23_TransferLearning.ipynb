{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e71728",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Machine Learning\n",
    "### Sommersemester 2023\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWUmcKKjtwXL"
   },
   "source": [
    "# Transfer Learning mit TensorFlow\n",
    "\n",
    "basiert auf dem Google Beispiel [*Transfer learning with TensorFlow Hub*](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub)\n",
    "(Tensorflow, 2018, Apache 2.0 Lizenz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGNpmn43C0O6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    import tensorflow_hub as hub\n",
    "except:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install tensorflow_hub\n",
    "    import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4YuF5HvpM1W"
   },
   "source": [
    "## Ein vortrainiertes ImageNet Modell verwenden\n",
    "\n",
    "Nicht immer müssen Modelle selbst trainiert werden.\n",
    "Zu verschiedene Anwendungsbereichen gibt es vortrainierte Modelle, die man direkt verwenden kann.\n",
    "Ein Beispiel ist die Bildklassifikation.\n",
    "Es gibt einige bekannte Neuronale Faltungsnetze (z.B. *Inception*, *ResNet*, *MobileNet* ...) die für die Klassifikation von Bildern eingesetzt werden können.\n",
    "Wir wollen ein solches, vortrainiertes Modell verwenden, um zu erkennen, welches Objekt auf einem Foto agebildet ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEY_Ow5loN6q"
   },
   "source": [
    "### Ein Modell auswählen\n",
    "\n",
    "Für diese Demo werden wir ein [MobileNetV2 Model](https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2) von [TensorFlow Hub](https://www.tensorflow.org/hub) verwenden.\n",
    "Auf dieser Plattform gibt es [viele weitere Modelle](https://tfhub.dev/s?q=tf2&module-type=image-classification), die man ebenfalls zur für diese Bildklassifikationsaufgabe verwenden könnte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "feiXojVXAbI9"
   },
   "outputs": [],
   "source": [
    "classifier_model =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_6bGjoPtzau"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(classifier_model, output_shape=[1001])\n",
    "])\n",
    "classifier.build([None, *IMAGE_SHAPE, 3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwZXaoV0uXp2"
   },
   "source": [
    "### Eine Bildklassifikation durchführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQItP1i55-di"
   },
   "source": [
    "Als Erstes wollen wir das Modell ausprobieren.\n",
    "Wir laden ein Bild aus dem Netz herunter und skalieren es auf die vom Modell verwendete Bildgröße.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "w5wDjXNjuXGD",
    "outputId": "288a7476-9c15-4a5c-9a94-bc8b11e2c289"
   },
   "outputs": [],
   "source": [
    "sample_img = tf.keras.utils.get_file('image.jpg','https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Dreysaczens_Antivir.jpg/640px-Dreysaczens_Antivir.jpg')\n",
    "\n",
    "sample_img = Image.open(sample_img).resize(IMAGE_SHAPE)\n",
    "sample_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun machen wir aus dem Bild ein Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEmmBnGbLxPp",
    "outputId": "41edec85-a8d5-4f89-833b-b44218621803"
   },
   "outputs": [],
   "source": [
    "oldtype = type(sample_img)\n",
    "sample_img = np.array(sample_img)/255.0\n",
    "newtype = type(sample_img)\n",
    "print(f\"Von {oldtype} zu {newtype}\")\n",
    "sample_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ic8OEEo2b73"
   },
   "source": [
    "Wir sehen, dass unser Bild nun als 3-Tupel abgespeichert ist.\n",
    "Die einzelnen Dimensionen sind die Höhe und Breite des Bildes (je $224$) sowie die einzelnen Pixelwerte ($3$).\n",
    "Das MobileNet Modell kann allerdings auf einen ganzen *Batch* von Bildern gleichzeitig angewendet werden und erwartet daher in der ersten Dimension die ID des Bildes.\n",
    "Wir müssen also aus dem 3-Tupel ein 4-Tupel machen, wobei die erste Dimension keine Daten enthält"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = sample_img.reshape(-1,*IMAGE_SHAPE,3)\n",
    "result = classifier.predict(input_image)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKzjqENF6jDF"
   },
   "source": [
    "Das Resultat der Vorhersage ist ein Vektor mit 1001 Einträgen.\n",
    "Jeder Eintrag beinhaltet den *Logit*-Wert für eine bestimmte Klasse von Objekten.\n",
    "Zur Erinnerung: Ein Logit ist der natürliche Logarithmus einer Chance, wobei die Chance $\\frac{p}{1-p}$ als Wahrscheinlichkeit $p$ durch Gegenwahrscheinlichkeit $1-p$ definiert ist.\n",
    "\n",
    "Um die *wahrscheinlichste* Klasse zu bestimmen, muss man also den Index des Maximums in diesem Array finden.\n",
    "Das funktioniert in NumPy mit der `argmax` Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgXb44vt6goJ",
    "outputId": "542486f9-84b7-48c4-827e-35666054cfcc"
   },
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(result[0], axis=-1)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrxLMajMoxkf"
   },
   "source": [
    "### Die Vorhersage dekodieren\n",
    "\n",
    "Nun möchten wir natürlich noch wissen, welche Klasse hinter der ID steckt.\n",
    "Da MobileNEt ein Klassifikator für den `ImageNet` Datensatz ist, können wir die Klassen von ImageNet zurate ziehen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ij6SrDxcxzry"
   },
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://github.com/fhswf/datasets/raw/main/ImageNetLabelsDe.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "plt.imshow(sample_img)\n",
    "plt.axis('off')\n",
    "predicted_class_name = imagenet_labels[predicted_class]\n",
    "plt.title(\"Vorhersage: \" + predicted_class_name.title());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Bestimmen Sie die Klassen mit zweit- bis fünfhöchsten Wahrscheinlichkeit (bzw. Logits).\n",
    "Um diese Klassen zu bestimmen, ist die NumPy Funktion `np.argsort` hilfreich. Sie sortiert das Array aufsteigend, gibt aber die ursprünglichen Indizes der sortierten Daten zurück und nicht deren Werte.\n",
    "Beachten Sie, dass Result ein zweidimensionales Array ist.\n",
    "Übergeben Sie also am einfachsten das Teil-Array `result[0]` an `np.argsort`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-888845bc97aad96b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amfzqn1Oo7Om"
   },
   "source": [
    "##  Transfer Learning mit Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-nIpVJ94xrw"
   },
   "source": [
    "Wir haben nun gesehen, das wir MobileNet zum Klassifizieren von Bildern verwenden können.\n",
    "Allerdings wird uns dieses (und alle weiteren für den ImageNet Datensatz trainierte Modelle) nur eine Klasse vorhersagen, die in den ursprünglichen 1000 Kategorien.\n",
    "(Die 1001 Kategorie ist übrigens für die Klasse *nicht bestimmbar* bestimmt. Diese wird aber i.d.R. nicht verwendet.)\n",
    "\n",
    "Nun stellt sich die Frage, wie man Objekte klassifizieren kann, die im ursprünglichen Datensatz nicht enthalten sind, bzw. deren Label nicht vorkommen.\n",
    "Eine naiver Ansatz wäre, einen neuen Trainingsdatensatz mit allen Bildern (also der ImageNet Bilder und der *eigenen* Bilder) zu erstellen, und ein neues Netz zu trainieren.\n",
    "Das wäre sehr zeitaufwendig, da das Neuronale Netz *von Grund auf neu Lernen* müsste.\n",
    "Und eigentlich haben wir Ja schon ein Netz, das Bilder unterscheiden kann.\n",
    "Wir wollen diesem Netz nur die *zusätzlichen Kategorien beibringen*.\n",
    "\n",
    "Genau dies ist der Ansatz von **Transfer Learning**.\n",
    "Wir nehmen ein bestehendes, trainiertes Modell (z.B. MobileNet) und verändern nur die hinteren Schichten, sodass das Netz die neuen Kategorien zu unterscheiden lernt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z93vvAdGxDMD"
   },
   "source": [
    "### Eigener Datensatz\n",
    "\n",
    "Für dieses Beispiel verwenden wir den Tensorflow *Flowers* Datensatz in dem verschiedene Arten von Blumen enthalten sind.\n",
    "Wir laden ihn aus dem Netz herunter und erstellen einen Trainingsdatensatz, indem wir die Methode `image_dataset_from_directory` mit dem Ornernamen der entpackten Bilder aufrufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrIUV3V0xDL_",
    "outputId": "feb207ed-29b9-4307-cb97-efdae8b490dd"
   },
   "outputs": [],
   "source": [
    "data_root = tf.keras.utils.get_file(\n",
    "  'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "   untar=True)\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  str(data_root),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCrSRlomEIZ4"
   },
   "source": [
    "Der Datensatz beinhaltet 5 Arten von Blumen.\n",
    "Die Namen der Klassen benennen wir hier ins Deutsche um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFgDHs6VEFRD",
    "outputId": "483f1cea-9f48-4094-95e5-02b4b2f3b3b0"
   },
   "outputs": [],
   "source": [
    "class_names = np.array(train_ds.class_names)\n",
    "print(\"Klassen (englisch):\", class_names)\n",
    "train_ds.class_names = ['Gaensebluemchen', 'Loewenzahn', 'Rosen', 'Sonnenblumen', 'Tulpen']\n",
    "class_names = np.array(train_ds.class_names)\n",
    "print(\"Klassen (deutsch):\", train_ds.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0Btd0V3C8h4"
   },
   "source": [
    "Die Daten unserer Bilder sind Pixelwerte im Integer Format, die TensorFlow Hub Modelle für Bildverarbeitung erwarten allerdings Fließkommazahlen im Bereich `[0, 1]`.\n",
    "Wir verwenden hier `Rescaling` aus dem Modul `tf.keras.layers.experimental.preprocessing` um die Daten zu transformieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "img_scaler = Rescaling(1.0/255)\n",
    "train_ds = train_ds = train_ds.map(lambda x, y: (img_scaler(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW-BUJ-NC7y-"
   },
   "source": [
    "Die nächsten beiden Anweisungen dienen der Performance Verbesserung beim Trainieren.\n",
    "Tensorflow soll die Bilder, die als nächstes VErarbeitet werden bereits vorab laden.\n",
    "Dieses Prinzip heißt *Prefetching* und wird allgemein eingesetzt um Wartezeiten für Eingabe-Operationen möglichst zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmJMKFw7C4ki"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun die Bilddaten (effizient) Batch-weise verarbeiten.\n",
    "In der folgenden Code-Zelle TEsten wir eine Schleife die die Bild-Daten durchlaufen würde und geben uns die Dimensionen des Batches und der Label aus.\n",
    "Nach dem ersten Durchlauf beenden wir die Schleife und haben einen Satz von Bildern und Labels unter den Referenzen `image_batch` bzw. `labels_batch` geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0JyiEZ0imgf",
    "outputId": "141d8cd9-e9c1-4328-b94f-86d9c9f5f904"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape, labels_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gTN7M_GxDLx"
   },
   "source": [
    "### Normales ImageNet Modell auf eigene Daten anwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3fvrZR8xDLv"
   },
   "source": [
    "Bevor wir ein neues Modell trainieren, wollen wir prüfen, wie unser MobileNet Modell mit den Blumen-Datensatz klar kommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcFeNcrehEue"
   },
   "outputs": [],
   "source": [
    "result_batch = classifier.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wK2ky45hlyS",
    "outputId": "9d1fab97-69d3-49fa-8ef7-9c1b5fec20f5"
   },
   "outputs": [],
   "source": [
    "predicted_class_names = imagenet_labels[np.argmax(result_batch, axis=-1)]\n",
    "predicted_class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmvSWg9nxDLa"
   },
   "source": [
    "Wir können nun prüfen, welche Ausgaben das Modell für unsere Blumenbilder vorhersagt.\n",
    "ImageNet beinhaltet außer den Gänseblümchen keine unsere Klassen und daher liegt das Modell in den meisten Fällen falsch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "IXTB22SpxDLP",
    "outputId": "b4283394-cd46-4b41-922b-4bb47f369cce"
   },
   "outputs": [],
   "source": [
    "true_label_batch = class_names[labels_batch]\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    # In Klammern die \"echten\" Labels\n",
    "    plt.title(predicted_class_names[n].title() + \"\\n(\" + true_label_batch[n].title() + \")\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"ImageNet predictions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzV457OXreQP"
   },
   "source": [
    "### Ein *Headless Model* laden\n",
    "\n",
    "Neben den volltrainierten Modellen gibt es auf *TensorFlow Hub* auch Modellvarianten, die zum *Weitertrainieren* bestimmt sind.\n",
    "Bei diesen Modellen sind die voll-verbundenen *Klassifikationsschichten* nachträglich entfernt.\n",
    "Die Schichten können nun mit den neuen Daten nachtrainiert werden.\n",
    "Das bedeutet, wir passen das generelle Modell auf unseren Datensatz an.\n",
    "Dabei verliert es die Fähigkeit, die vielen vorherigen Klassen zu unterscheiden, gewinnt aber die Fähigkeit, die neuen Klassen zu erkennen.\n",
    "\n",
    "Alle Modelle unter [diesem Link](https://tfhub.dev/s?module-type=image-feature-vector&q=tf2) können so nachtrainiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bw8Jf94DSnP"
   },
   "outputs": [],
   "source": [
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgwmHugQF-PD"
   },
   "source": [
    "Wir verwenden nun das geladene Modell als *Feature Extractor*. Das heißt als das vortrainierte Modell wird uns die *Eigenschaften* eines Bildes berechnen, die zusätzlichen, neuen Schichten berechnen aus diesen Eigenschaften die zugehörigen Klassen.\n",
    "\n",
    "Unser *Feature Extractor* wird dabei wie ein Layer zum Keras Modell hinzugefügt.\n",
    "Damit dieser Teil des Modells nicht mit trainiert wird (er ist ja bereits trainiert), setzen wir den Parameter `trainable=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wB030nezBwI"
   },
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QzVdu4ZhcDE"
   },
   "source": [
    "Der *Feature Extractor* liefert einen Vektor mit 1280 Einträgen, die die *Eigenschaften* des Bildes beschreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Of7i-35F09ls"
   },
   "outputs": [],
   "source": [
    "feature_batch = feature_extractor_layer(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPVeouTksO9q"
   },
   "source": [
    "### Klassifizierende Schichten ergänzen\n",
    "\n",
    "Nun fehlen dem Modell noch die End-Schichten, in denen die eigentliche Klassifikation der Bilder geschieht.\n",
    "Wir fügen dem Modell also noch einen `Dense`-Layer mit fünf Neuronen hinzu, je eines für die zu unterscheidenden Klassen von Blumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQq_kCWzlqSu"
   },
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHbXQqIquFxQ"
   },
   "source": [
    "### Das Modell trainieren\n",
    "\n",
    "Zunächst kompilieren wir das erstellte Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xRx8Rjzm67O"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58-BLV7dupJA"
   },
   "source": [
    "Nun verwenden wir die `fit`-Methode, um das Modell zu trainieren. Um das Training möglichst kurz zu halten, werden wir nur zwei Epochen auswerten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JI0yAKd-nARd"
   },
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.batch_losses = []\n",
    "        self.batch_acc = []\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_losses.append(logs['loss'])\n",
    "        self.batch_acc.append(logs['acc'])\n",
    "        self.model.reset_metrics()\n",
    "\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "\n",
    "history = model.fit(train_ds, epochs=2, callbacks=[batch_stats_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd0N272B9Q0b"
   },
   "source": [
    "Wir können beobachten, dass nach nur 2 Epochen das Modell bereits gute Ergebnisse liefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5RfS1QIIP-P"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(batch_stats_callback.batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uvX11avTiDg"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(batch_stats_callback.batch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb__ZN8uFn-D"
   },
   "source": [
    "### Das Modell überprüfen\n",
    "\n",
    "Nun können wir unseren Testdaten für den *Flowers* Datensatz erneut auswerten.\n",
    "Das angepasste Modell sollte nun deutlich bessere Ergebnisse liefern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGbEf5l1I4jz"
   },
   "outputs": [],
   "source": [
    "predicted_batch = model.predict(image_batch)\n",
    "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]\n",
    "true_label_batch = class_names[labels_batch]\n",
    "\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    plt.title(predicted_label_batch[n].title() + \"\\n(\" + true_label_batch[n].title() + \")\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Model predictions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRcJnAABr22x"
   },
   "source": [
    "## Modell abspeichern\n",
    "\n",
    "Das Trainieren von Modellen ist zeitaufwendig und daher sollte man Ergebnisse immer abspeichern.\n",
    "Wir exportieren hier das gesamte Tensorflow Modell in einen lokalen Ordner mit aktuellem Zeitstempel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf ./saved_models/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLcqg-RmsLno"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "t = time.time()\n",
    "\n",
    "export_path = \"./saved_models/{}\".format(int(t))\n",
    "model.save(export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhQ9liIUsPsi"
   },
   "source": [
    "Nun können wir das Modell aus dem abgespeicherten Dateien wiederherstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nI5fvkAQvbS"
   },
   "outputs": [],
   "source": [
    "reloaded = tf.keras.models.load_model(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jor83-LqI8xW"
   },
   "outputs": [],
   "source": [
    "result_batch = model.predict(image_batch)\n",
    "reloaded_result_batch = reloaded.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnZO14taYPH6"
   },
   "outputs": [],
   "source": [
    "abs(reloaded_result_batch - result_batch).max()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "W_tvPdyfA-BL"
   ],
   "name": "Kopie von transfer_learning_with_hub.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
