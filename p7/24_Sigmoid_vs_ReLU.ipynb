{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad6a27c",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Machine Learning\n",
    "### Sommersemester 2023\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def make_spirals(N=100, dim=2, classes=2, random_state=0):\n",
    "    np.random.seed(random_state)\n",
    "    X = np.zeros((N*classes,dim))\n",
    "    num_train_examples = X.shape[0]\n",
    "    y = np.zeros(N*classes, dtype='uint8')\n",
    "    for j in range(classes):\n",
    "        ix = range(N*j,N*(j+1))\n",
    "        r = np.linspace(0.0,1,N) # radius\n",
    "        k = classes+1\n",
    "        t = np.linspace(j*k,(j+1)*k,N) + np.random.randn(N)*0.2 # theta\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        y[ix] = j\n",
    "    return X, y\n",
    "\n",
    "N=60\n",
    "dim=2\n",
    "classes=3\n",
    "random_state=0\n",
    "\n",
    "X, y = make_spirals(N, dim, classes, random_state)\n",
    "fig = plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-1,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b7b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, multi_class='ovr').fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabeb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('Set1', 3)\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "fig = plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.4)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, ec='black', cmap=cmap)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfa99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    x = 1/(1+np.exp(-x))\n",
    "    return x\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return (x)*(1-x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def relu_grad(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to train a three layer neural net with either RELU or sigmoid nonlinearity via vanilla grad descent\n",
    "\n",
    "def three_layer_net(NONLINEARITY,X,y, model, step_size, reg, epochs=1000):\n",
    "    #parameter initialization\n",
    "    \n",
    "    h= model['h']\n",
    "    h2= model['h2']\n",
    "    W1= model['W1']\n",
    "    W2= model['W2']\n",
    "    W3= model['W3']\n",
    "    b1= model['b1']\n",
    "    b2= model['b2']\n",
    "    b3= model['b3']\n",
    "    \n",
    "    \n",
    "    # some hyperparameters\n",
    "\n",
    "\n",
    "    # gradient descent loop\n",
    "    num_examples = X.shape[0]\n",
    "    plot_array_1=[]\n",
    "    plot_array_2=[]\n",
    "    plot_array_3=[]\n",
    "    for i in range(epochs):\n",
    "\n",
    "        #FOWARD PROP\n",
    "\n",
    "        if NONLINEARITY== 'RELU':\n",
    "            hidden_layer = relu(np.dot(X, W1) + b1)\n",
    "            hidden_layer2 = relu(np.dot(hidden_layer, W2) + b2)\n",
    "            scores = np.dot(hidden_layer2, W3) + b3\n",
    "\n",
    "        elif NONLINEARITY == 'SIGM':\n",
    "            hidden_layer = sigmoid(np.dot(X, W1) + b1)\n",
    "            hidden_layer2 = sigmoid(np.dot(hidden_layer, W2) + b2)\n",
    "            scores = np.dot(hidden_layer2, W3) + b3\n",
    "\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "        # compute the loss: average cross-entropy loss and regularization\n",
    "        corect_logprobs = -np.log(probs[range(num_examples),y])\n",
    "        data_loss = np.sum(corect_logprobs)/num_examples\n",
    "        reg_loss = 0.5*reg*np.sum(W1*W1) + 0.5*reg*np.sum(W2*W2)+ 0.5*reg*np.sum(W3*W3)\n",
    "        loss = data_loss + reg_loss\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(\"iteration %d: loss %f\" % (i, loss))\n",
    "\n",
    "        if i % 1 == 0:\n",
    "            predicted_class = np.argmax(scores, axis=1)\n",
    "            ca = np.mean(predicted_class == y)\n",
    "            plot_array_3.append(ca)\n",
    "        else:\n",
    "            plot_array_3.append(ca)\n",
    "        \n",
    "        # compute the gradient on scores\n",
    "        dscores = probs\n",
    "        dscores[range(num_examples),y] -= 1\n",
    "        dscores /= num_examples\n",
    "\n",
    " \n",
    "        # BACKPROP HERE\n",
    "        dW3 = (hidden_layer2.T).dot(dscores)\n",
    "        db3 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "        if NONLINEARITY == 'RELU':\n",
    "\n",
    "            #backprop ReLU nonlinearity here\n",
    "            dhidden2 = np.dot(dscores, W3.T)\n",
    "            dhidden2[hidden_layer2 <= 0] = 0\n",
    "            \n",
    "            dW2 =  np.dot( hidden_layer.T, dhidden2)\n",
    "            \n",
    "            plot_array_2.append(np.sum(np.abs(dW2))/np.sum(np.abs(dW2.shape)))\n",
    "            db2 = np.sum(dhidden2, axis=0)\n",
    "            dhidden = np.dot(dhidden2, W2.T)\n",
    "            dhidden[hidden_layer <= 0] = 0\n",
    "            \n",
    "        elif NONLINEARITY == 'SIGM':\n",
    "\n",
    "            #backprop sigmoid nonlinearity here\n",
    "            dhidden2 = dscores.dot(W3.T)*sigmoid_grad(hidden_layer2)\n",
    "            dW2 = (hidden_layer.T).dot(dhidden2)\n",
    "            \n",
    "            plot_array_2.append(np.sum(np.abs(dW2))/np.sum(np.abs(dW2.shape)))\n",
    "            db2 = np.sum(dhidden2, axis=0)\n",
    "            dhidden = dhidden2.dot(W2.T)*sigmoid_grad(hidden_layer)\n",
    "\n",
    "        \n",
    "        dW1 =  np.dot(X.T, dhidden)\n",
    "        plot_array_1.append(np.sum(np.abs(dW1))/np.sum(np.abs(dW1.shape)))\n",
    "        db1 = np.sum(dhidden, axis=0)\n",
    "\n",
    "        # add regularization\n",
    "        dW3+= reg * W3\n",
    "        dW2 += reg * W2\n",
    "        dW1 += reg * W1\n",
    "        \n",
    "        #option to return loss, grads -- uncomment next comment\n",
    "        grads={}\n",
    "        grads['W1']=dW1\n",
    "        grads['W2']=dW2\n",
    "        grads['W3']=dW3\n",
    "        grads['b1']=db1\n",
    "        grads['b2']=db2\n",
    "        grads['b3']=db3\n",
    "        #return loss, grads\n",
    "        \n",
    "        \n",
    "        # update\n",
    "        W1 += -step_size * dW1\n",
    "        b1 += -step_size * db1\n",
    "        W2 += -step_size * dW2\n",
    "        b2 += -step_size * db2\n",
    "        W3 += -step_size * dW3\n",
    "        b3 += -step_size * db3\n",
    "    # evaluate training set accuracy\n",
    "    if NONLINEARITY == 'RELU':\n",
    "        hidden_layer = relu(np.dot(X, W1) + b1)\n",
    "        hidden_layer2 = relu(np.dot(hidden_layer, W2) + b2)\n",
    "    elif NONLINEARITY == 'SIGM':\n",
    "        hidden_layer = sigmoid(np.dot(X, W1) + b1)\n",
    "        hidden_layer2 = sigmoid(np.dot(hidden_layer, W2) + b2)\n",
    "    scores = np.dot(hidden_layer2, W3) + b3\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print ('training accuracy: %.2f' % (np.mean(predicted_class == y)))\n",
    "    #return cost, grads\n",
    "    return plot_array_1, plot_array_2, plot_array_3, W1, W2, W3, b1, b2, b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a603aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize toy model, train sigmoid net\n",
    "\n",
    "h=50\n",
    "h2=50\n",
    "num_train_examples = X.shape[0]\n",
    "\n",
    "model={}\n",
    "model['h'] = h # size of hidden layer 1\n",
    "model['h2']= h2# size of hidden layer 2\n",
    "model['W1']= 0.1 * np.random.randn(dim,h)\n",
    "model['b1'] = np.zeros((1,h))\n",
    "model['W2'] = 0.1 * np.random.randn(h,h2)\n",
    "model['b2']= np.zeros((1,h2))\n",
    "model['W3'] = 0.1 * np.random.randn(h2,classes)\n",
    "model['b3'] = np.zeros((1,classes))\n",
    "\n",
    "(sigm_array_1, sigm_array_2, sigm_array_3, s_W1, s_W2,s_W3, s_b1, s_b2,s_b3) = \\\n",
    "    three_layer_net('SIGM', X,y,model, step_size=1e-1, reg=1e-3, epochs=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f81f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-initialize model, train relu net\n",
    "\n",
    "model={}\n",
    "model['h'] = h # size of hidden layer 1\n",
    "model['h2']= h2# size of hidden layer 2\n",
    "model['W1']= 0.1 * np.random.randn(dim,h)\n",
    "model['b1'] = np.zeros((1,h))\n",
    "model['W2'] = 0.1 * np.random.randn(h,h2)\n",
    "model['b2']= np.zeros((1,h2))\n",
    "model['W3'] = 0.1 * np.random.randn(h2,classes)\n",
    "model['b3'] = np.zeros((1,classes))\n",
    "\n",
    "(relu_array_1, relu_array_2, relu_array_3, r_W1, r_W2,r_W3, r_b1, r_b2,r_b3) = \\\n",
    "    three_layer_net('RELU', X,y,model, step_size=1e-1, reg=1e-3, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,8))\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "p0 = ax1.plot(np.array(sigm_array_1), \":\", c='r', label=\"Sigmoid 1. Schicht\")\n",
    "p1 = ax1.plot(np.array(sigm_array_2), \":\", c='g', label=\"Sigmoid 2. Schicht\")\n",
    "p2 = ax2.plot(np.array(sigm_array_3), \":\", c='b', label=\"Sigmoid Accuracy\")\n",
    "p3 = ax1.plot(np.array(relu_array_1), \"-\", c='r', label=\"ReLU 1. Schicht\")\n",
    "p4 = ax1.plot(np.array(relu_array_2), \"-\", c='g', label=\"ReLU 2. Schicht\")\n",
    "p5 = ax2.plot(np.array(relu_array_3), \"-\", c='b', label=\"ReLU Accuracy\")\n",
    "plt.title('Summe der absoluten Gewichte')\n",
    "\n",
    "# added these three lines\n",
    "p = p0+p1+p2+p3+p4+p5\n",
    "labs = [l.get_label() for l in p]\n",
    "ax1.legend(p, labs, loc=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap = plt.get_cmap('Set1', 3)\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = np.dot(sigmoid(np.dot(sigmoid(np.dot(np.c_[xx.ravel(), yy.ravel()], s_W1) + s_b1), s_W2) + s_b2), s_W3) + s_b3\n",
    "Z = np.argmax(Z, axis=1)\n",
    "Z = Z.reshape(xx.shape)\n",
    "fig = plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.4)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, ec='black', cmap=cmap)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4005918a",
   "metadata": {},
   "source": [
    "### Referenzen\n",
    "\n",
    "[1] Andrej Karpathy, [\"*Neural Networks Case Study*\"](https://cs231n.github.io/neural-networks-case-study/), Kurs CS231n: \"Convolutional Neural Networks for Visual Recognition\", Stanford University"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
