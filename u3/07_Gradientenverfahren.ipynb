{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e9b847b",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Machine Learning\n",
    "### Sommersemester 2023\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Gradientenverfahren\n",
    "\n",
    "In diesem Notebook geht es erneut um Regressionsprobleme.\n",
    "Nur, dass wir diesmal nicht die Funktionen zur Linearen Regression aus der Scikit-Learn Bibliothek verwenden, sonder die Lernalgorithmen selber implementieren.\n",
    "\n",
    "Um die Wirkungsweise der Algorithmen besser bewerten zu können, verwenden wir im Beispiel keine *echten* Daten, sondern wir generieren einen sythetischen Datensatz mit nur einer unabhängigen Variable.\n",
    "\n",
    "Die generierten Datenpunkte sollen sich anhand einer Geraden orientieren und um diese Gerade mit einer gewissem gewissen, normalverteilten Fehler (*Rauschen*) angeordnet sein.\n",
    "Wichtig sind hier die beiden Parameter `ziel_theta_0` und `ziel_theta_1`, die den Achsenabschnitt bzw. die Steigung der Geraden angeben.\n",
    "Unsere Modellfunktion sollte diese beiden Parameter möglichst gut annähern, da Sie die *wirkliche* Verteilung der Daten angeben. \n",
    "\n",
    "Wir werden wie folgt vorgehen:\n",
    "1. Datensatz erzeugen\n",
    "2. Python-Funktionen für Modell- und Kostenfunktion entwickeln\n",
    "3. Kostenfunktion visualisieren\n",
    "4. Gradientenverfahren implementieren\n",
    "5. Parameter für die Modellfunktion optimieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "size = 1000\n",
    "mux = 0\n",
    "stdx = 1\n",
    "X = np.random.normal(mux,stdx,size)\n",
    "shiftx = np.min(X)\n",
    "X = X.reshape(size,1)\n",
    "\n",
    "munoise = 0\n",
    "stdnoise = .5\n",
    "noise = np.random.normal(munoise,stdnoise,size)\n",
    "noise = noise.reshape(size,1)\n",
    "\n",
    "ziel_theta_0 = 12\n",
    "ziel_theta_1 = 4.4\n",
    "\n",
    "y = ziel_theta_0 + ziel_theta_1*X + noise\n",
    "print(np.shape(y))\n",
    "\n",
    "#plt.hist(noise, bins=100)\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um den Bias-Parameter mitverarbeiten zu können, fügen wir eine Spalte zur Datenmatrix hinzu. Jedem Datenpunkt wird dazu ein neues $x_0 = 1$ zugeordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.c_[np.ones((size, 1)), X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsere Modellfunktion $h_{\\Theta}(X)$ definieren wir als Python Funktion `h(X,theta)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X,theta):\n",
    "    '''Modellfunktion h\n",
    "        X ist eine Matrix. Jede Zeile entspricht einem Datenpunkt.    \n",
    "    '''\n",
    "    return X@theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Kostenfunktion $J(\\Theta)$ definieren wir als Funktion `J_mse(X, y, theta)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_mse(X, y, theta):\n",
    "    # Aus theat einen Numpy Spaltenvektor machen\n",
    "    theta = np.array(theta).reshape(-1,1)\n",
    "    # Kosten berechnen\n",
    "    me = h(X,theta)-y\n",
    "    r = me.T@me / (2*len(X))\n",
    "    # Kosten als Skalar zurückgeben\n",
    "    return r.item(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun die Kosten für beliebige Schätzungen von $\\Theta$ berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_mse(X_new, y, [0.0,0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der folgenden Code-Zelle visualisieren wir die Kosten als 3D-Graph.\n",
    "Die $x$ und $y$ Achse geben die verschieden Werte für die Parameter $\\Theta_0$ bzw. $\\Theta_1$ an, auf der $z$-Achese sind die entsprechenden Kosten aufgetragen.\n",
    "\n",
    "Die Funktion ist wie eine *Schüssel* geformt, mathematisch gesehen würde man sagen, sie ist *konvex*.\n",
    "Bei dieser Funktion wird das Gradientfahren garantiert das (globale) Optimum finden.\n",
    "Die Wahl der Parameter ist optimal am tiefsten Punkt der \"Schüssel\".\n",
    "Der Gradientabstieg wird sich, unter gewissen Bedingungen, in jedem Schritt diesem Optimum nähern.\n",
    "Bei jeder Wahl der Parameter $\\Theta_0$ und $\\Theta_1$ wird berechnet, in welcher Richtung der steilste Abstieg hin zum Optimum erfolgen muss.\n",
    "In dieser Richtung wählt man einen neue Parameter-Satz aus und berechnet die Kosten an diesem Punkt, berechnet erneut den Gradienten, usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "t0 = np.linspace(-50, 75, 30)\n",
    "t1 = np.linspace(-50, 75, 30)\n",
    "\n",
    "xx, yy = np.meshgrid(t0, t1)\n",
    "xy = list(zip(np.reshape(xx,-1),np.reshape(yy,-1)))\n",
    "zz = np.array([J_mse(X_new, y, np.array(i).reshape(-1,1)) for i in xy]).reshape(np.shape(xx))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot_surface(xx, yy, zz, cmap=cm.coolwarm)\n",
    "\n",
    "ax.set_xlabel(r'$\\theta_0$')\n",
    "ax.set_ylabel(r'$\\theta_1$')\n",
    "ax.set_zlabel(r'J($\\theta$)=MSE($\\theta$)')\n",
    "\n",
    "\n",
    "plt.savefig(\"Kostenfunktion3D.png\",transparent=True, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Ebene kann man diese dreidimensionale Ansicht als Konturdiagramm darstellen.\n",
    "Diese Art von Diagramm ist eine Art Draufsicht auf die Funktion entlang der $z$-Achse.\n",
    "Die $z$-Werte werden dabei farblich kodiert dargestellt.\n",
    "Sie kennen diese Darstellung vermutlich als *Höhenlinien* aus geografischen Landkarten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.contour(xx, yy, zz, 10, extend='both') #, vmin=0, vmax=1000000)\n",
    "plt.xlabel(r'$\\theta_0$')\n",
    "plt.ylabel(r'$\\theta_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der folgenden Zelle definieren wir das Gradientenverfahren als Python-Funktion `gradient_descent`.\n",
    "Die Funktion bekommt als als Parameter u.a. die Anzahl von Iterationen übergeben, nach der das Verfahren stoppen soll.\n",
    "Es gibt für das Gradientenverfahren auch andere, evtl. sogar bessere Abbruchkriterien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, iterationen):\n",
    "    kosten = []\n",
    "    # Aus theat einen Numpy Spaltenvektor machen\n",
    "    theta = np.array(theta).reshape(-1,1)\n",
    "    for iter in range(iterationen):\n",
    "        kosten.append(J_mse(X, y, theta))\n",
    "        gradient = 1/len(y) * (X.T @ (X @ theta - y))\n",
    "        theta = theta - (alpha * gradient)\n",
    "    return theta, kosten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen nun das Verfahren ausprobieren und das oben definierte Modell minimieren.\n",
    "In der folgenden Code-Zelle werden wir die Funktion `gradient_descent` mehrfach mit verschiedenen Lernraten zwischen $0.03$ und $2.0$ ausprobieren.\n",
    "\n",
    "Wir sehen, dass die verschiedenen Lernraten mehr oder weniger schnell zum Ziel führen.\n",
    "Bei der Lernrate $2.0$ scheint das Verfahren sogar zu divergieren, also in die *falsche Richtung* zu laufen.\n",
    "Dies ist ein Zeichen dafür, dass die Lernrate zu hoch gewäht ist, und das Gradientenverfahren in zu großen Schritten, quasi *über das Optimum hinwegspringt*.\n",
    "Kleinere Lernraten füren sicher zum Ziel, haben aber den Nachteil, dass sehr viele Schritte benötigt werden.\n",
    "\n",
    "Die Wahl der Lernrate ist allgemein ein kritischer Faktor für die Qualität eines Optimierungsalgorithmus, wie *Gradient Descent*.\n",
    "Viele Verfahren bestimmen die Lernrate aufgrund der einzelnen Optimierungsschritte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 = [0,0]\n",
    "\n",
    "laeufe = []\n",
    "alphas = [0.03, 0.1, .4, 1.8]\n",
    "for alpha in alphas:\n",
    "    theta_gd, kosten = gradient_descent(X_new, y, theta_0, alpha, 30)\n",
    "    laeufe.append(kosten)\n",
    "    \n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "for i in range(0,len(laeufe)):\n",
    "    plt.scatter(range(0,len(laeufe[i])),laeufe[i][0:], marker=\"x\", label=r'$\\alpha=$'+str(alphas[i]))\n",
    "\n",
    "plt.legend(loc='upper center', ncol=2)\n",
    "plt.ylim([-20,120])\n",
    "plt.ylabel(r'$J(\\Theta)$')\n",
    "plt.xlabel(r'Epoche')\n",
    "plt.savefig(\"lernrate.png\",transparent=True, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Abbildung in der nächsten Code-Zelle Zeigt, wie nah die durch das Gradientenverfahren bestimmte Lösung am tatsächlichen Optimum liegt.\n",
    "Beachten Sie die Wertebereiche der Parameter im Konturdiagramm.\n",
    "Die *Höhenlinien* umfassen nur sehr wenige Zehntel und die beiden Lösungen liegen selbst dabei sehr dicht zusammen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "theta_gd, kosten = gradient_descent(X_new, y, theta_0, 0.3, 20)\n",
    "theta_opt = np.linalg.inv(X_new.T @ X_new) @ X_new.T @ y\n",
    "\n",
    "scope = .5\n",
    "\n",
    "t0 = np.linspace(theta_gd[0]-scope, theta_gd[0]+scope, 30)\n",
    "t1 = np.linspace(theta_gd[1]-scope, theta_gd[1]+scope, 30)\n",
    "\n",
    "xx, yy = np.meshgrid(t0, t1)\n",
    "xy = list(zip(np.reshape(xx,-1),np.reshape(yy,-1)))\n",
    "zz = np.array([J_mse(X_new, y, np.array(i).reshape(-1,1)) for i in xy]).reshape(np.shape(xx))\n",
    "\n",
    "plt.contour(xx, yy, zz, 10, extend='both') #, vmin=0, vmax=1000000)\n",
    "plt.xlabel('Theta_0')\n",
    "plt.ylabel('Theta_1')\n",
    "theta_gd_plt = theta_gd.T[0]\n",
    "theta_opt_plt = theta_opt.T[0]\n",
    "plt.scatter(theta_gd_plt[0],theta_gd_plt[1],c=\"r\")\n",
    "print(theta_gd)\n",
    "print(theta_opt)\n",
    "plt.xlabel(r'$\\theta_0$')\n",
    "plt.ylabel(r'$\\theta_1$')\n",
    "plt.annotate('Optimum (Normalgleichung)', xy=theta_opt_plt, xytext=(theta_opt_plt[0]-scope/2, theta_opt_plt[1]+scope/2),\n",
    "            arrowprops=dict(facecolor='black', width=.5, headwidth=5))\n",
    "plt.annotate('Approximiert (Gradientenverfahren)', xy=theta_gd_plt, xytext=(theta_gd_plt[0]-scope/2, theta_gd_plt[1]-scope/2),\n",
    "            arrowprops=dict(facecolor='black', width=.5, headwidth=5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der nächsten Code-Zelle wollen wir darstellen, wie sich das Gradientenverfahren in seinen einzelenen Iterationen Schritt für Schritt dem Optimum nähert.\n",
    "Wir sehen, dass alle Schritte die Parameter auf direktem Weg zum Optimum bewegen.\n",
    "\n",
    "Die Code-Zelle erzeugt übrigens auch eine GIF Grafik, die Sie sich in einem Anzeigeprogramm ansehen können.\n",
    "Darin sind die Schritte im zeitlichen Verlauf simuliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "scope = 2\n",
    "\n",
    "t0 = np.linspace(theta_gd[0]-scope, theta_gd[0]+scope, 30)\n",
    "t1 = np.linspace(theta_gd[1]-scope, theta_gd[1]+scope, 30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.contour(xx, yy, zz, 10, extend='both') #, vmin=0, vmax=1000000)\n",
    "plt.xlabel(r'$\\theta_0$')\n",
    "plt.ylabel(r'$\\theta_1$')\n",
    "limx = ax.get_xlim()\n",
    "limy = ax.get_ylim()\n",
    "\n",
    "#Probiere verschiedene Werte für alpha:\n",
    "alpha=.3\n",
    "iterationen = 30\n",
    "theta_0 = np.array([theta_gd[0]+scope, theta_gd[1]+scope]).reshape(2,1)\n",
    "\n",
    "p0 = []\n",
    "p1 = []\n",
    "kosten = []\n",
    "\n",
    "def gd_plot(i):\n",
    "    global theta_0\n",
    "    global kosten\n",
    "    v0 = theta_0.item(0)\n",
    "    v1 = theta_0.item(1)\n",
    "    p0.append(v0)\n",
    "    p1.append(v1)\n",
    "    ax.plot(p0, p1, \"-x\", color='r')\n",
    "    ax.set_xlim(limx)\n",
    "    ax.set_ylim(limy)\n",
    "    kosten.append(J_mse(X_new, y, theta_0))\n",
    "    gradient = 1/len(y) * (X_new.T @ (X_new @ theta_0 - y))\n",
    "    theta_0 = theta_0 - (alpha * gradient)\n",
    "    if(i==iterationen-1):\n",
    "        ax.scatter(theta_0.item(0), theta_0.item(1), marker=\"x\", c=\"b\", s=100, zorder=i+10)\n",
    "        plt.savefig(\"lernrate_GD_contour.png\",transparent=True, dpi=300)\n",
    "    return\n",
    "\n",
    "\n",
    "anim = FuncAnimation(fig, gd_plot, frames=np.arange(0, iterationen), interval=100, repeat=True)\n",
    "anim.save('gd_contour_80.gif', dpi=80, writer='pillow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](gd_contour_80.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch in der Abbildung der Fehlerrate sehen wir, das jeder Schritt die Wahl der Parameter verbessert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(kosten)),kosten[0:], \"x-\", label=str(alphas[i]))\n",
    "plt.savefig(\"lernrate_GD.png\",transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der folgenden Code-Zelle verwenden wir nun eine Variante des Gratienverfahrens, den sogenannten **Mini-Batch Gradientenabstieg**.\n",
    "Beim Mini-Batch Verfahren werden für die Neuberechnung der Parameter nicht alle, sondern nur ein gewisser Teil von $k$ Datenpunkten ausgewertet.\n",
    "Die Konstante $k$ wird *batch*-Größe genannt und ist im Normalfall deutlich kleiner als die Anzahl der Datenpunkte $n$ im Trainigsdatensatz.\n",
    "\n",
    "Wir verwenden hier eine *batch*-Größe von 64 Datenpunkten, die außerdem jeweils zufällig auswählen.\n",
    "Statt die Kosten für alle 1000 Punkte zu berechnen, bestimmen wir also nur die Kosten für 64 zufällige Datenpunkte.\n",
    "Danach berechnen wir den Gradienten, verschieben die Parameter-Werte in Richtung dieses Gradienten und wählen erneut 64 zufällige Punkte für den nächsten Schritt aus.\n",
    "\n",
    "Wir sehen, dass sich die Wahl der Parameter beim Mini-Batch Gradientenabstieg nicht so stringent dem Minimum nähert, wie beim vollständigen Verfahren.\n",
    "Allerdings kommen wir deutlich schneller zum Ziel, da die Parameter bereits nach der Berechnung von wenigen Datenpunkten korrigiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.contour(xx, yy, zz, 10, extend='both') #, vmin=0, vmax=1000000)\n",
    "plt.xlabel(r'$\\Theta_0$')\n",
    "plt.ylabel(r'$\\Theta_1$')\n",
    "limx = ax.get_xlim()\n",
    "limy = ax.get_ylim()\n",
    "\n",
    "alpha=.3\n",
    "iterationen = 30\n",
    "#theta_0 = np.random.randn(1,2)\n",
    "theta_0 = np.array([theta_gd[0]+scope, theta_gd[1]+scope]).reshape(2,1)\n",
    "\n",
    "p0 = []\n",
    "p1 = []\n",
    "kosten = []\n",
    "batchsize = 64\n",
    "\n",
    "def gd_plot(i):\n",
    "    global theta_0\n",
    "    global kosten\n",
    "    v0 = theta_0.item(0)\n",
    "    v1 = theta_0.item(1)\n",
    "    p0.append(v0)\n",
    "    p1.append(v1)\n",
    "    ax.plot(p0, p1, \"-x\", color='r')\n",
    "    ax.set_xlim(limx)\n",
    "    ax.set_ylim(limy)\n",
    "    idx = np.random.randint(X.shape[0], size=batchsize)\n",
    "    xi = X_new[idx,:]\n",
    "    yi = y[idx,:]\n",
    "    kosten.append(J_mse(xi, yi, theta_0))\n",
    "    gradient = 1/len(yi) * (xi.T @ (xi @ theta_0 - yi))\n",
    "    theta_0 = theta_0 - (alpha * gradient)\n",
    "    if(i==iterationen-1):\n",
    "        ax.scatter(theta_0.item(0), theta_0.item(1), marker=\"x\", c=\"b\", s=400, zorder=i+10)\n",
    "        plt.savefig(\"lernrate_SGD_contour.png\",transparent=True, dpi=300)\n",
    "    return\n",
    "\n",
    "anim = FuncAnimation(fig, gd_plot, frames=np.arange(0, iterationen), interval=200, repeat=True)\n",
    "anim.save('bgd_contour_80.gif', dpi=80, writer='pillow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](bgd_contour_80.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch bei den Kosten sehen wir, dass nicht jeder Schritt eine Verbesserung bringt.\n",
    "Allerdings benötigt der Mini-Batch Gradientenabstieg nur sehr wenige Epochen, um sich dem Optimum recht gut zu nähern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "gens = np.linspace(0, len(kosten)/(len(X_new)/batchsize), len(kosten))\n",
    "\n",
    "plt.plot(gens,kosten[0:], \"x-\")\n",
    "plt.ylabel(r'$J_{\\Theta}(x)$')\n",
    "plt.xlabel('Epoche')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple und polynomiale Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im obigen Beispiel haben wir ein Regressionsproblem mit nur einer unabhängigen Variabel (oder auch *Merkmal*) betrachtet.\n",
    "Dies ist hilfreich für die Visulaisierung, aber natürlich nicht der Normalfall.\n",
    "In der Praxis haben unsere Datensätze weit mehr als nur ein Merkmal.\n",
    "Wir habe dies ja bereits in den vorherigen Beispielen zur linearen Regression gesehen.\n",
    "\n",
    "In der multiplen Linearen Regression gehen wir davon aus, dass sich die abhängige Variable als Linearkombination der unabhängigen Variablen voraussagen lässt.\n",
    "Was ist aber, wenn ein solcher linearer Zusammenhang nicht besteht?\n",
    "Dann kann es sein, dass ein nicht-linearer Zusammenhang besteht und sich die Zielvariable $y$ durch eine Polynomfunktion der unabhängigen Variablen erklären lässt.\n",
    "\n",
    "Bei einem derartigen Zusammenhang kann uns die sogenannte **polynomiale Regression** helfen.\n",
    "Die polynomiale Regression ist ein Spezialfall der multiplen linearen Regression, bei der zusätzlich zu den unabhängigen Variablen noch die polynome bis zum Grad $n$ mit in die Merkmalsvariablen aufgenommen werden.\n",
    "Bei zwei unabhängigen Variablen $x_0$ und $x_1$ herhalten wir für ein Polynom zweiten Grades also die Modellfunktion:\\\n",
    "$\\hat{y} = \\Theta_0 + \\Theta_1 x_0 + \\Theta_2 x_1 + \\Theta_3 x_0^2 + \\Theta_4 x_1^2 + \\Theta_5 x_0 x_1$\n",
    "\n",
    "Im folgenden Beispiel verwenden wir erneut einen generierten Datensatz mit nur einer unabhängigen Variablen $x$.\n",
    "Unser Modell verwendet ein Polynaom zweiten Grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "size = 100\n",
    "mux = 0\n",
    "stdx = 0.5\n",
    "#X = np.random.normal(mux,stdx,size)\n",
    "X = np.random.uniform(-1, 1, size)\n",
    "xmin = np.min(X)\n",
    "xmax = np.max(X)\n",
    "\n",
    "X = np.c_[X, X*X]\n",
    "\n",
    "munoise = 0\n",
    "stdnoise = 0.4\n",
    "noise = np.random.normal(munoise,stdnoise,size)\n",
    "noise = noise.reshape(size,1)\n",
    "\n",
    "ziel_theta_0 = 12\n",
    "ziel_theta_1 = -4.4\n",
    "ziel_theta_2 = 28.1\n",
    "\n",
    "y = ziel_theta_0 + ziel_theta_1*X[:,[0]] + ziel_theta_2*X[:,[1]] + noise\n",
    "\n",
    "plt.scatter((X[:,[0]]).reshape(size), y.reshape(size))\n",
    "\n",
    "vone = (np.ones(size)).reshape(size,1)\n",
    "X = np.concatenate((vone, X), 1)\n",
    "\n",
    "\n",
    "\n",
    "#theta_0 = np.random.randn(X.shape[1],1)\n",
    "theta_0 = [0,0,0]\n",
    "theta, costs = gradient_descent(X, y, theta_0, 0.8, 50)\n",
    "\n",
    "xi = np.linspace(xmin,xmax,30)\n",
    "yi = [ theta.item(0) + theta.item(1)*i + theta.item(2)*i*i for i in xi ]\n",
    "plt.plot(xi,yi, c='red')\n",
    "plt.show()\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Overfitting ist ein ein generelles Problem im Maschinellen Lernen.\n",
    "Auch bei der Wahl der Polynomfunktion für eine Polynomiale Regression kann zu Überanpassung kommen.\n",
    "Wenn man dem Modell so hohe Freiheitsgrade gibt, dass die Funktion sich den Daten sehr genau anpassen kann, verliert das Modell die Fähigkeit zu *Veralgemeinern*.\n",
    "\n",
    "Das folgende Beispiel zeigt, etwas überspitzt, was passiert, wenn man eine Polynomfunktion an **wenige** Daten anpasst.\n",
    "Im Beispiel transformieren wir einen Datensatz in einen Datensatz, der die Variablen für das Polynom 5. Grades enthält.\n",
    "Die *normale* Lineare Regression passt sich den Daten **ideal** an.\n",
    "Aber offensichtlich ist das entstehende Modell nicht gut, denn es spiegelt nicht den *Verlauf* der Daten wieder.\n",
    "\n",
    "Setzt man **Regularisierung**, z.B. in Form der **Lasso-** oder **Ridge-Regression** ein, sind die entstehenden Modellfunktionen deutlich sinnvoller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "samples = 300\n",
    "size = 10\n",
    "mux = 0\n",
    "stdx = 0.5\n",
    "#X = np.random.normal(mux,stdx,size)\n",
    "X = np.random.uniform(-1, 1, size)\n",
    "xmin = np.min(X)\n",
    "xmax = np.max(X)\n",
    "X = np.c_[X, X*X]\n",
    "\n",
    "\n",
    "xi = np.linspace(xmin,xmax,samples)\n",
    "xi = np.c_[xi, xi*xi]\n",
    "vone = (np.ones(samples)).reshape(samples,1)\n",
    "xi = np.concatenate((vone, xi), 1)\n",
    "\n",
    "munoise = 0\n",
    "stdnoise = 1.4\n",
    "noise = np.random.normal(munoise,stdnoise,size)\n",
    "noise = noise.reshape(size,1)\n",
    "\n",
    "ziel_theta_0 = 12\n",
    "ziel_theta_1 = -4.4\n",
    "ziel_theta_2 = 28.1\n",
    "\n",
    "y = ziel_theta_0 + ziel_theta_1*X[:,[0]] + ziel_theta_2*X[:,[1]] + noise\n",
    "\n",
    "plt.scatter((X[:,[0]]).reshape(size), y.reshape(size))\n",
    "\n",
    "vone = (np.ones(size)).reshape(size,1)\n",
    "X = np.concatenate((vone, X), 1)\n",
    "    \n",
    "\n",
    "##model = LinearRegression()\n",
    "##model.fit(X, y)\n",
    "poly_reg=PolynomialFeatures(degree=5)\n",
    "X_poly=poly_reg.fit_transform(X)\n",
    "poly_reg.fit(X_poly,y)\n",
    "model=LinearRegression()\n",
    "model.fit(X_poly,y)\n",
    "xi_poly = poly_reg.fit_transform(xi)\n",
    "ys = model.predict(xi_poly)\n",
    "\n",
    "\n",
    "\n",
    "model = Ridge(alpha=0.5)\n",
    "model.fit(X_poly, y)\n",
    "yr = model.predict(xi_poly)\n",
    "\n",
    "model = Lasso(alpha=0.5)\n",
    "model.fit(X_poly, y)\n",
    "yl = model.predict(xi_poly)\n",
    "\n",
    "\n",
    "plt.plot(xi[:,[1]],ys, label=\"Standard\", c='red')\n",
    "plt.plot(xi[:,[1]],yr, label=\"Ridge\")\n",
    "plt.plot(xi[:,[1]],yl, label=\"Lasso\")\n",
    "#plt.ylim(np.min(y)-100,np.max(y)+100)\n",
    "plt.legend()\n",
    "plt.savefig(\"regularisierung.png\",transparent=True, dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
