{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ead9d2",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Machine Learning\n",
    "### Sommersemester 2023\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Logistische Regression (Beispiel *Fashion MNIST*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der MNIST (Modified National Institute of Standards and Technology) Datensatz von handschriftlichen Ziffern wird sehr verbreitet eingesetzt, um Machine Learning Algorithmen zu demonstrieren und zu bewerten.\n",
    "Er lässt sich mit Scikit-Learn komfortabel über die Funktion `fetch_mldata('MNIST original')` aus dem Repository http://mldata.org laden.\n",
    "Von dort wurde der Datensatz bisher über 370.000-mal heruntergeladen.\n",
    "\n",
    "Allerdings sind die MNIST Daten nicht mehr unbedingt zeitgemäß.\n",
    "Mit modernen Verfahren läßt sich eine Präzision mit deutlich über 99% erreichen, weswegen der Datensatz heutzutage allgemein als \"zu leicht\" eingeschätzt wird.\n",
    "\n",
    "In diesem Aufgabenblatt verwenden wir daher einen Datensatz, der sehr ähnlich wie MNIST aufgebaut ist, für den eine Klassifikation aber etwas schwieriger ist.\n",
    "Es handelt sich um den sogenannten [*Fashion MNIST*](https://github.com/zalandoresearch/fashion-mnist) Datensatz, den der Online-Versandhändler Zalando entwickelt und zur freien Verfügung gestellt hat.\n",
    "\n",
    "Der Datensatz besteht aus 70.000 Bildern von Kleidungsstücken, Schuhen und Taschen und Kleidern.\n",
    "Jedes Bild besteht aus 784 (28×28) Pixeln, die einzelnen Pixel werden als Grauwert im Bereich 0 bis 255 gespeichert.\n",
    "Bei einem Byte pro Pixel und 70.000 Bildern à 784 Pixeln, benötigt der Datensatz ca. 50MB am Speicherplatz.\n",
    "\n",
    "Die Daten sind auf 4 Dateien aufgeteilt:\n",
    "- `train-images-idx3-ubyte.gz`: 60.000 Bilder als Traingnsdatensatz \n",
    "- `train-labels-idx1-ubyte.gz`: Die zum Traingnsdatensatz zugehörigen Label\n",
    "- `test-images-idx3-ubyte.gz`: 10.000 Bilder als Testdatensatz\n",
    "- `test-labels-idx1-ubyte.gz`: Die zum Testdatensatz zugehörigen Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "files = ['train-images-idx3-ubyte.gz','train-labels-idx1-ubyte.gz',\n",
    "         't10k-images-idx3-ubyte.gz','t10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "for f in files:\n",
    "    if not os.path.isfile(f):\n",
    "        url = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/' + f\n",
    "        r = requests.get(url)\n",
    "        with open(f, 'wb') as f:  \n",
    "            f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Funktion `load_mnist` können die Rohdaten, die im gzip Format vorliegen, in NumPy-Arrays geladen.\n",
    "Die Funktion liefert ein Tupel aus den Bilddaten sowie den Labels zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    '''\n",
    "    Quelle: https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "    \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\". Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\n",
    "    '''\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_10 = load_mnist('.', kind='train')\n",
    "X_test, y_test_10 = load_mnist('.', kind='t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Anzeigen eines Bildes, können wir die Funktion `imshow` aus dem Modul `matplotlib.pyplot` verwenden.\n",
    "Da die Pixel eines Bildes als fortlaufendes Array abgelegt sind, müssen wir das Bild zuvor noch mit der Funktion `reshape` in das richtige Format bringen.\n",
    "Um ein zufällig ausgewähltes Bild anzuzeigen, verwenden wir die Funktion `random.randint(x,y)`, die eine Zufallszahl im Bereich `x` bis `y-1` liefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm\n",
    "\n",
    "sample = random.randint(0,len(y_train_10))\n",
    "img = X_train[sample].reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "\n",
    "print(\"Klasse \", y_train_10[sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Trainieren Sie ein  logistisches Regressionsmodell zur Erkennung von Pullovern\n",
    "\n",
    "Verwenden Sie die [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) Klasse aus Scikit-learn.\n",
    "Als *Solver* soll das Modell `liblinear` benutzen und beim Trainieren maximal 10 Iterationen verwenden.\n",
    "\n",
    "Berechnen Sie die *Classification Accuracy* über die Scikit-learn Funktion `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a91b28611a03280a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "accuracy_train = None\n",
    "accuracy_test = None\n",
    "\n",
    "# Setze nur eine Klasse auf 1, alle anderen auf 0\n",
    "klasse = 0\n",
    "y_train = (y_train_10 == klasse) * 1\n",
    "y_test = (y_test_10 == klasse) * 1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "print(\"Treffequote Trainingsdaten: %.2f%%\" % (100*accuracy_train))\n",
    "print(\"Treffequote Testdaten: %.2f%%\" % (100*accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-941984e0760af4d3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert \"max_iter\" in _i\n",
    "assert \"liblinear\" in _i\n",
    "assert \"LogisticRegression\" in _i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir uns dem eigentlichen Klassifikationsproblem mit mehreren Klassen widmen.\n",
    "Wir verwenden an dieser Stelle ein logistisches Regressionsmodell mit einer one-versus-all Strategie, um die Klassen für die einzelnen Kleidungsstücke und Accessoires vorauszusagen.\n",
    "\n",
    "Im Vergleich zu den bisher betrachteten Datensätzen, sind die Fashion MNIST Daten sehr umfangreich.\n",
    "Daher ist auch die Berechnung der Modellparameter wesentlich komplexer und zeitaufwendiger als bei den Beispielen zuvor.\n",
    "Wir sollten daher darauf achten, dass einmal berechnete Parameter nicht verlorengehen, etwa, weil das Programm, bzw. das Python-Notebook geschlossen wird.\n",
    "\n",
    "Um die berechneten Modellparameter in eine Datei zu speichern, verwenden wir die Bibliothek Pickle (zu deutsch *einmachen*, *einlegen* oder auch *Essiggurke*).\n",
    "Mit Pickle kann man Python Objekte serialisiert in eine Datei schreiben.\n",
    "Dabei bleibt die komplette Struktur des Objekts intakt, sodass das Objekt aus der Datei wieder vollständig hergestellt werden kann.\n",
    "\n",
    "Sobald ein Modell berechnet wurde, speichern wir es in eine Datei.\n",
    "Wird die Code-Zelle später erneut ausgeführt, laden wir die Daten aus der Datei ein, anstatt das Modell erneut zu trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, y_train = load_mnist('.', kind='train')\n",
    "X_test, y_test = load_mnist('.', kind='t10k')\n",
    "\n",
    "filename = 'logreg_fashion_mnist.mod'\n",
    "if os.path.isfile(filename):\n",
    "    logreg = pickle.load(open(filename, 'rb'))\n",
    "else:    \n",
    "    #logreg = LogisticRegression(multi_class=\"ovr\")\n",
    "    logreg = LogisticRegression(max_iter=10, solver='lbfgs',multi_class='ovr', n_jobs=-1)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    pickle.dump(logreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Überprüfung der Vorhersagegenauigkeit können wir die sklearn-Funktion `score` verwenden.\n",
    "Sie berechnet die den Anteil der korrekten Vorhersagen über alle Klassen.\n",
    "Eine Vorhersage ist korrekt, wenn die Vorhergesagte Klasse mit der tatsächlichen Klasse übereinstimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "saved_model = pickle.load(open(filename, 'rb'))\n",
    "result = saved_model.score(X_test, y_test)\n",
    "print(\"Vorhersagegenauigkeit (Testdaten): %.2f%%\" % (result*100))\n",
    "result = saved_model.score(X_train, y_train)\n",
    "print(\"Vorhersagegenauigkeit (Trainingsdaten): %.2f%%\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Berechnen Sie die Vorhersagegenauigkeit ohne die `score`-Funktion zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-29262aebbede1677",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# acc_test: the ratio of correctly predected labels to the size of the test set (between 0 and 1)\n",
    "\n",
    "acc_test = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(\"Vorhersagegenauigkeit (Testdaten): %.2f%%\" % (acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c7434893394691c6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "assert 0 <= acc_test <= 1\n",
    "assert acc_test == saved_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Konfusionsmatrix ist eine Tabelle, die für jede Klasse die Anzahl der übereinstimmenden Vorhersagen darstellt.\n",
    "In den Zeilen der Matrix sind die tatsächlichen Klassen aufgetragen, in den Spalten die vorhergesagten Klassen.\n",
    "Die Werte auf der Diagonalen der Matrix sind demnach korrekte Vorhersagen, die Werte ausserhalb der Diagonalen sind fehlerhafte Vorhersagen.\n",
    "\n",
    "Die Konfusionsmatrix kann mit der Funktion `sklearn.metrics.confusion_matrix` berechnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = logreg.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Berechnen Sie die Konfusionsmatrix ohne die Funktion `confusion_matrix` zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-72cb7cc6e418d4d0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# classes: Anzahl der Klassen\n",
    "# cm: Konfusionsmatrix (Tatsächliche Klassen in Zeilen, vorhergesagte Klassen in Spalten)\n",
    "\n",
    "classes = sorted(list(set(y_test)))\n",
    "cm = []\n",
    "for i in classes:\n",
    "    pass\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-36e912aaa83d63ef",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "cm = np.array(cm)\n",
    "n = len(set(y_test))\n",
    "assert cm.shape == (n, n)\n",
    "assert np.array_equal(cm, confusion_matrix(y_test, y_pred))\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weitere Metriken zur Bewertung des Modells sind die Relevanz (auch Genauigkeit oder positiver Vorhersagewert; engl. precision oder positive predictive value) und die Sensitivität (auch Richtig-positiv-Rate oder Trefferquote; engl. sensitivity oder recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_test_c0 = [y_test==0][0]*1\n",
    "y_pred_c0 = [y_pred==0][0]*1\n",
    "\n",
    "precision_score(y_test_c0, y_pred_c0), recall_score(y_test_c0, y_pred_c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/422px-Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Berechnen Sie die Relevanz und die Sensitivität ohne die Funktionen `precision_score` und `recall_score` zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-40cb2290216aec8a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def precision_recall(y_true_c0, y_pred_c0):\n",
    "    '''\n",
    "    Berechne zuerst die Anzahl der\n",
    "     - true positives  (TP)\n",
    "     - false positives (FP)\n",
    "     - false negatives (FN)\n",
    "    Mit diesen Werten kann dann die Relevanz und die Sensitivitaet \n",
    "    berechent werden.\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-993b6d2420050694",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "assert precision_recall(y_test_c0, y_pred_c0) == (precision_score(y_test_c0, y_pred_c0), recall_score(y_test_c0, y_pred_c0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
